{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca36e0c2",
   "metadata": {},
   "source": [
    "(choosing-alpha)=\n",
    "# Prior information about Specificity and Sensitivity\n",
    "\n",
    "In this notebook, we will consider the bivariate beta distribution explained\n",
    "previously to jointly model sensitivity and specificity. If $\\gamma_s$ and\n",
    "$\\gamma_e$ are, respectively sensitivity and specificity, we will have that\n",
    "\n",
    "$$(\\gamma_s, \\gamma_e) \\sim \\operatorname{Bivariate Beta}(\\alpha_1, \\dots,\n",
    "\\alpha_4).$$\n",
    "\n",
    "Suppose we have prior knowledge about these parameters and we want to use this\n",
    "information to help to parametrize the marginal beta distributions. Here I\n",
    "present some consequences of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae3293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pystan as ps\n",
    "\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from utilits import ParameterAlpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2506b",
   "metadata": {},
   "source": [
    "Below we can see the the function that calculates the moments of the\n",
    "distribution we showed last [chapter](moments-summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83410c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments_calculus(alpha): \n",
    "    \n",
    "    tilde_alpha = alpha[0]+alpha[1]+alpha[2]+alpha[3]\n",
    "    \n",
    "    E_X = (alpha[0]+alpha[1])/tilde_alpha\n",
    "    E_Y = (alpha[0]+alpha[2])/tilde_alpha\n",
    "    \n",
    "    Var_X = (1/(tilde_alpha*(tilde_alpha+1)))*E_X*(alpha[2] + alpha[3])\n",
    "    Var_Y = (1/(tilde_alpha*(tilde_alpha+1)))*E_Y*(alpha[1] + alpha[3])\n",
    "    \n",
    "    den = np.log(alpha[0] + alpha[1]) + np.log(alpha[2]+alpha[3]) + np.log(alpha[0]+alpha[2]) + np.log(alpha[1]+alpha[3])\n",
    "    den = np.exp(-0.5*den)\n",
    "    Cor_XY = (alpha[0]*alpha[3] - alpha[1]*alpha[2])*den\n",
    "    \n",
    "    return (E_X, E_Y, Var_X, Var_Y, Cor_XY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff5ebe",
   "metadata": {},
   "source": [
    "## From prior information to moments estimation \n",
    "\n",
    "The Bivariate Beta has four parameters and each marginal beta distribution has two parameters. We obtained that when  $m_1 = E[X], m_2 = E[Y], v_1 = Var[X],$ and $v_2 = Var[Y]$ are fixed, there is a solution if, and only if, \n",
    "\n",
    "\\begin{equation}\n",
    "  v_2  = \\frac{v_1(1 - m_2)}{m_1(1-m_1)},\n",
    "\\end{equation}\n",
    "\n",
    "and when the solution exists, there are infinitely many, described by the ray:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\{(1,-1,-1,1)\\alpha_4 + k : \\alpha_4 > 0\\}, \n",
    "$$\n",
    "\n",
    "such that $k = \\left((m_1 + m_2 - 1)\\tilde{\\alpha}, (1-m_2)\\tilde{\\alpha},\n",
    "(1-m_1)\\tilde{\\alpha}, 0\\right)$ and $\\tilde{\\alpha} = \\alpha_1 + \\dots +\n",
    "\\alpha_4$. \n",
    "\n",
    "If we fix $\\rho = Cor(X,Y)$, instead of fixing $Var[Y]$, the solution is\n",
    "unique. Now we gonna evaluate how big the difference of $v_2$ to the value of its\n",
    "inferred equation. As explained in the dissertation, we can write $\\alpha_1,\n",
    "\\alpha_2$, and $\\alpha_3$ as function of $\\alpha_4$, and $\\alpha_4$ as\n",
    "function of $\\rho$, when this is fixed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ccdf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha123_from_4(alpha4, m1, m2, v1): \n",
    "     \n",
    "    C = (m1 - m1*m1 - v1)/v1 \n",
    "    alpha1 = (m1 + m2 - 1)*C + alpha4 \n",
    "    alpha2 = (1 - m2)*C - alpha4 \n",
    "    alpha3 = (1 - m1)*C - alpha4 \n",
    "    \n",
    "    return (alpha1, alpha2, alpha3)\n",
    "\n",
    "def find_alpha4_from_corr(m1, m2, v1, rho):\n",
    "    \n",
    "    exp = rho + np.sqrt((1-m1)*(1-m2)/(m1*m2))\n",
    "    exp *= np.sqrt(m1*m2*(1-m1)*(1-m2))*(m1 - m1*m1 - v1)\n",
    "    alpha4 = exp/v1\n",
    "    \n",
    "    return alpha4\n",
    "\n",
    "def var_error(m1, m2, v1, v2): \n",
    "    \n",
    "    return abs(v2 - v1*(1-m2)/(m1*(1 - m1)))/v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a80a8a",
   "metadata": {},
   "source": [
    "Below we set the parameter $\\alpha$ and calculate the respective moments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac87f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5660377358490566 0.4716981132075472 0.004548870693406115 0.004614796355629392 -0.3165549546879246\n"
     ]
    }
   ],
   "source": [
    "m1, m2, v1, v2, rho = moments_calculus([10, 20, 15, 8])\n",
    "print(m1, m2, v1, v2, rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eae7ea",
   "metadata": {},
   "source": [
    "We already know there is no solution with these specified values. The relative\n",
    "is error for $v_2$ is \n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{|v_2  - \\frac{v_1(1 - m_2)}{m_1(1-m_1)}|}{v_2}.\n",
    "\\end{equation}\n",
    "\n",
    "In the case we are seeing, it is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788032fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1199999999999997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_error(m1,m2,v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23937d3e",
   "metadata": {},
   "source": [
    "And we succeeded in finding the correct values from the functions we wrote. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a59c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000000000000005 20.0 14.999999999999998 8.000000000000005\n"
     ]
    }
   ],
   "source": [
    "alpha4 = find_alpha4_from_corr(m1,m2,v1,rho)\n",
    "alpha1, alpha2, alpha3 = alpha123_from_4(alpha4, m1, m2, v1)\n",
    "print(alpha1, alpha2, alpha3, alpha4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28cc01",
   "metadata": {},
   "source": [
    "## Variance error for different studies \n",
    "\n",
    "Now we know that there is an error inherent to the modeling, so we would like\n",
    "to see how this error happens in different areas. We consider some studies\n",
    "from [this\n",
    "article](https://link.springer.com/article/10.1007/s12350-018-01485-y) that\n",
    "contains information about the estimated sensitivity and specificity and\n",
    "95%-CI for several studies. The data is divided in: First column is the\n",
    "estimated mean; Second column the lower bound; Third column the upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3256bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sens = np.array([\n",
    "    [0.44, 0.37, 0.51],\n",
    "    [0.54, 0.35, 0.72],\n",
    "    [0.61, 0.39, 0.8], \n",
    "    [0.81,0.73,0.87],\n",
    "    [0.36,0.26,0.47],\n",
    "    [0.96,0.88,0.99]\n",
    "])\n",
    "data_spec = np.array([\n",
    "    [0.98, 0.94,0.99],\n",
    "    [0.98,0.89,1.0],\n",
    "    [0.9, 0.6,0.98], \n",
    "    [0.46,0.34,0.58],\n",
    "    [0.94,0.82,0.98],\n",
    "    [0.82,0.74,0.88]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e7a93",
   "metadata": {},
   "source": [
    "Remember that we want to obtain the expressions of the mean and variance for\n",
    "each random variable. The ideia is to find the parameters of the beta\n",
    "distribution marginals with the specific mean and approximated 95%-interval.\n",
    "The procedure is minimize the quadratic difference between the interval and\n",
    "the approximated one. The functions are below. \n",
    "\n",
    "We know that $\\mu = \\frac{\\alpha}{\\alpha + \\beta}$ is the mean of the beta\n",
    "distribution. Then $\\beta = \\frac{1 - \\mu}{\\mu}\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a57a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_cumulative_95(alpha, a, b, mu): \n",
    "    \n",
    "    bet = find_beta(alpha, mu)\n",
    "    X = beta(a = alpha, b = bet)\n",
    "    return (X.cdf(b) - X.cdf(a) - 0.95)**2\n",
    "    \n",
    "find_alpha = lambda mu, a, b: minimize(fun = diff_cumulative_95, x0 = (1,), args = (a, b, mu), bounds = [(0,np.inf)])\n",
    "find_beta = lambda alpha, mu: alpha*(1 - mu)/mu\n",
    "find_var = lambda alpha, bet: beta(a = alpha, b = bet).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db366a19",
   "metadata": {},
   "source": [
    "Now we can apply these functions to data. In special, we calculate the error in the system of equations to determine $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423e7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros((data_spec.shape[0], 5))\n",
    "\n",
    "for i in range(data_spec.shape[0]): \n",
    "    \n",
    "    m1 = data_sens[i,0]\n",
    "    a1 = data_sens[i,1]\n",
    "    b1 = data_sens[i,2]\n",
    "    m2 = data_spec[i,0]\n",
    "    a2 = data_spec[i,1]\n",
    "    b2 = data_spec[i,2]\n",
    "    \n",
    "    alpha1 = find_alpha(m1, a1, b1).x[0]\n",
    "    beta1 = find_beta(alpha1, m1)\n",
    "    v1 = find_var(alpha1, beta1)\n",
    "    \n",
    "    alpha2 = find_alpha(m2, a2, b2).x[0]\n",
    "    beta2 = find_beta(alpha2, m2)\n",
    "    v2 = find_var(alpha2, beta2)\n",
    "    \n",
    "    results[i,:] = [m1,m2,v1,v2, var_error(m1,m2,v1,v2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3a96e",
   "metadata": {},
   "source": [
    "Below we observe that the error is not that big for these studies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7437d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = results[:,4]\n",
    "hist, bins = np.histogram(x, bins=20)\n",
    "logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "plt.hist(x, bins=logbins)\n",
    "plt.xscale('log')\n",
    "plt.title(r'Relative errors histogram of $v_2$ equation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c95a8e",
   "metadata": {},
   "source": [
    "## Optimizing the choice of parameters $\\alpha$ \n",
    "\n",
    "We saw before that the system with 5 equations has a solution iff $v_2$ relates to a function of $m_1, m_2$, and $v_1$. This means that usually we will not find values for $\\alpha$ that satisfies the knowledge of the input. To overcome this problem, we can minimize the sum of differences of the equations. Let $g  : \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$ be a loss function. Than, we want to minimize: \n",
    "\n",
    "$$\n",
    "    g\\left(m_1, \\dfrac{\\alpha_1+\\alpha_2}{\\tilde{\\alpha}}\\right) + \n",
    "    g\\left(m_2, \\dfrac{\\alpha_1+\\alpha_3}{\\tilde{\\alpha}}\\right) +  \n",
    "    g\\left(v_1, \\dfrac{(\\alpha_1+\\alpha_2)(\\alpha_3+\\alpha_4)}{\\tilde{\\alpha}^2(\\tilde{\\alpha}+1)}\\right) + \n",
    "    g\\left(v_2, \\dfrac{(\\alpha_1+\\alpha_3)(\\alpha_2+\\alpha_4)}{\\tilde{\\alpha}^2(\\tilde{\\alpha}+1)}\\right) + \n",
    "    g\\left(\\rho, \\frac{\\alpha_1\\alpha_4 - \\alpha_2\\alpha_3}{\\sqrt{(\\alpha_1+\\alpha_2)(\\alpha_3+\\alpha_4)(\\alpha_1+\\alpha_3 (\\alpha_2+\\alpha_4)}}\\right)\n",
    "$$\n",
    "\n",
    "such that $\\alpha_1, \\dots, \\alpha_4 > 0$. For instance, we can use the quadratic loss, the absolute loss, or other one. Since $m_i$ is much higher than $v_i$ ($i=1,2$) usually, one can think about a relative loss.  \n",
    "\n",
    "Here we will use $g(x,y) = (x - y)^2/x^2$. We also add a vetor parameter $c$\n",
    "of dimension four to have a weighted version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e53f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x,y: (x - y)**2/x**2\n",
    "\n",
    "def loss_function(alpha, m1, m2, v1, v2, rho, g, c = [1,1,1,1]): \n",
    "    \n",
    "    alpha_tilde = sum(alpha)\n",
    "    div = alpha_tilde*alpha_tilde*(alpha_tilde + 1)\n",
    "    \n",
    "    alpha_12 = alpha[0] + alpha[1]\n",
    "    alpha_34 = alpha[2] + alpha[3]\n",
    "    alpha_13 = alpha[0] + alpha[2]\n",
    "    alpha_24 = alpha[1] + alpha[3]\n",
    "    \n",
    "    obj  = c[0]*g(m1, alpha_12/alpha_tilde)\n",
    "    obj += c[1]*g(m2, alpha_13/alpha_tilde)\n",
    "    obj += c[2]*g(v1, alpha_12*alpha_34/div)\n",
    "    obj += c[3]*g(v2, alpha_13*alpha_24/div)\n",
    "    obj += g(rho, (alpha[0]*alpha[3] - alpha[1]*alpha[2])/(np.sqrt(alpha_12*alpha_34*alpha_13*alpha_24)))\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905c41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2, v1, v2, rho = moments_calculus([10, 20, 15, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13167f9",
   "metadata": {},
   "source": [
    "We are using the Trust Constraint algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "321a88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimizer = lambda m1, m2, v1, v2, rho, g: minimize(fun = loss_function, \n",
    "                                                 x0 = (1, 1, 1, 1), \n",
    "                                                 args = (m1, m2, v1, v2, rho, g),\n",
    "                                                 bounds = [(0, np.inf)]*4,\n",
    "                                                 method = 'trust-constr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4c6ae",
   "metadata": {},
   "source": [
    "Therefore we can obtain very similar values for the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efa4b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.99999839, 19.99999852, 15.0000007 ,  8.00000127])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimizer(m1,m2,v1,v2,rho, g).x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bd5cb",
   "metadata": {},
   "source": [
    "### Some remarks\n",
    "\n",
    "Sometimes the initial guess $x_0$ is very important as we can see below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd6afd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-31fea47f0948>:17: RuntimeWarning: invalid value encountered in sqrt\n",
      "  obj += g(rho, (alpha[0]*alpha[3] - alpha[1]*alpha[2])/(np.sqrt(alpha_12*alpha_34*alpha_13*alpha_24)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The $\\alpha$ values for $x_0$ = [1,1,1,1] : [ 5.95645337  9.57916884 18.26099607 24.06254864]\n",
      "The $\\alpha$ values for $x_0$ = [1,1,1,5] : [ 1.00000012  1.00000012  2.00000023 20.00000114]\n"
     ]
    }
   ],
   "source": [
    "m1, m2, v1, v2, rho = moments_calculus([1, 1, 2, 20])\n",
    "\n",
    "minimizer = lambda m1, m2, v1, v2, rho, g, x0: minimize(fun = loss_function, \n",
    "                                                 x0 = x0, \n",
    "                                                 args = (m1, m2, v1, v2, rho, g),\n",
    "                                                 bounds = [(0, np.inf)]*4,\n",
    "                                                 method = 'trust-constr')\n",
    "\n",
    "print(r'The $\\alpha$ values for $x_0$ = [1,1,1,1] : {}'.format(minimizer(m1,m2,v1,v2,rho,g, x0 = [1,1,1,1]).x))\n",
    "print(r'The $\\alpha$ values for $x_0$ = [1,1,1,5] : {}'.format(minimizer(m1,m2,v1,v2,rho,g, x0 = [1,1,1,5]).x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63862e",
   "metadata": {},
   "source": [
    "Other metrics can be considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8f73d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The $\\alpha$ values for $c$ = [1,1,1,1], g = quadratic : [1.00022465 5.00111486 6.00133688 3.00066687]\n",
      "The $\\alpha$ values for $c$ = [1,1,10,10], g = quadratic : [1.00002614 5.00012205 6.0001456  3.00007131]\n",
      "The $\\alpha$ values for $c$ = [1,1,1,1], g = relative quadratic : [1.00000012 5.00000005 6.00000004 2.99999992]\n",
      "The $\\alpha$ values for $c$ = [1,1,10,10], g = relative quadratic : [1.0000003  4.99999993 6.00000016 2.99999976]\n"
     ]
    }
   ],
   "source": [
    "m1, m2, v1, v2, rho = moments_calculus([1, 5, 6, 3])\n",
    "\n",
    "h = lambda x,y: (x - y)**2\n",
    "\n",
    "minimizer = lambda m1, m2, v1, v2, rho, g, c: minimize(fun = loss_function, \n",
    "                                                 x0 = [1,1,1,1], \n",
    "                                                 args = (m1, m2, v1, v2, rho, g, c),\n",
    "                                                 bounds = [(0, np.inf)]*4,\n",
    "                                                 method = 'trust-constr')\n",
    "\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,1,1], g = quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,h, c = [1,1,1,1]).x))\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,10,10], g = quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,h, c = [1,1,10,10]).x))\n",
    "\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,1,1], g = relative quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,g, c = [1,1,1,1]).x))\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,10,10], g = relative quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,g, c = [1,1,10,10]).x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c26034",
   "metadata": {},
   "source": [
    "In order to avoid numerical instability, the weighted quadratic loss can be\n",
    "useful. Other approaches consider working on the log space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "259dc193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The $\\alpha$ values for $c$ = [1,1,1,1], g = quadratic : [ 0.99980935  4.99903699 29.99420193  2.99941945]\n",
      "The $\\alpha$ values for $c$ = [1,1,10,10], g = quadratic : [ 1.00005621  5.00024359 30.0014424   3.00013576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-31fea47f0948>:17: RuntimeWarning: invalid value encountered in sqrt\n",
      "  obj += g(rho, (alpha[0]*alpha[3] - alpha[1]*alpha[2])/(np.sqrt(alpha_12*alpha_34*alpha_13*alpha_24)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The $\\alpha$ values for $c$ = [1,1,1,1], g = relative quadratic : [12.0611353  12.51811669 15.80903826 15.22546947]\n",
      "The $\\alpha$ values for $c$ = [1,1,10,10], g = relative quadratic : [ 1.00000053  4.99999876 29.99999809  3.00000013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasmoschen/anaconda3/envs/tcc-emap/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    }
   ],
   "source": [
    "m1, m2, v1, v2, rho = moments_calculus([1, 5, 30, 3])\n",
    "\n",
    "h = lambda x,y: (x - y)**2\n",
    "\n",
    "minimizer = lambda m1, m2, v1, v2, rho, g, c: minimize(fun = loss_function, \n",
    "                                                 x0 = [1,1,1,1], \n",
    "                                                 args = (m1, m2, v1, v2, rho, g, c),\n",
    "                                                 bounds = [(0, np.inf)]*4,\n",
    "                                                 method = 'trust-constr')\n",
    "\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,1,1], g = quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,h, c = [1,1,1,1]).x))\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,10,10], g = quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,h, c = [1,1,10,10]).x))\n",
    "\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,1,1], g = relative quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,g, c = [1,1,1,1]).x))\n",
    "print(r'The $\\alpha$ values for $c$ = [1,1,10,10], g = relative quadratic : {}'.format(minimizer(m1,m2,v1,v2,rho,g, c = [1,1,10,10]).x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c4896-b156-4d39-bbe7-28d45ea23181",
   "metadata": {},
   "source": [
    "## Mixing method to choose $\\alpha$\n",
    "\n",
    "The true solution to the system to find $\\alpha$ commonly has negative values. So the optimizer has a fight between the barrier in 0 and the function being smaller for small values. It leads to very small values and spoils the sampling from Dirichlet distribution. In that sense, we develop a mixing method that choose $\\alpha$ in order to have the means of sensibility and specificity fixed, while the other parameters are left to be optimized. This is done, because we believe that information about means may be more precise that variance. Moreover, its values are commonly larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42925ca0-2fd4-42f7-9fce-2ee0c410bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.188786462232764, 20.37725115580932, 15.282911552802306, 8.15105062102996)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat = ParameterAlpha().mix_solver(m1, m2, v1, v2, rho)\n",
    "alpha_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0614-26a4-4ed6-be59-14edc7404e5a",
   "metadata": {},
   "source": [
    "Note that these values are different from what we put. However look below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa16e01-e071-47bb-a2e5-36ab8cf783bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.453527824846111e-11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterAlpha().partial_loss_function(alpha_hat[2:], m1, m2, v1, v2, rho, g = ParameterAlpha().quadratic_error, c = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9981e65b-953b-4eb7-bb6e-a06a3525b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.000000000000014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterAlpha().partial_loss_function([15,8], m1, m2, v1, v2, rho, g = ParameterAlpha().quadratic_error, c = (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fd5d4-276a-4649-949f-bc0fb74d6f43",
   "metadata": {},
   "source": [
    "It says that our loss function produces an error of 2 for the correct values! Despite that, they produce very similar values of $m_1, m_2, v_1, v_2$ and $\\rho$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f64a1350-9acb-4488-864f-35cb917ef848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00, -8.27067230e-05, -8.39053711e-05,\n",
       "        8.02799138e-06])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = moments_calculus(alpha_hat)\n",
    "np.array(v) - np.array([m1,m2,v1,v2,rho])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c36aa-7a2e-4513-be55-4aeccdd5dd4a",
   "metadata": {},
   "source": [
    "This behaviour happens because we made some simplifications to the minimizer assuming the first two equations correct. In special, we are minimizing (for quadratic error): \n",
    "\n",
    "$$\n",
    "\\left(\\tilde{a} - \\frac{m_1(1 - m_1)}{v_1}\\right)^2 + \\left(\\tilde{a} - \\frac{m_2(1 - m_2)}{v_2}\\right)^2 + \\left(\\rho - \\frac{\\alpha_1\\alpha_4 - \\alpha_2\\alpha_3}{\\tilde{\\alpha}^2\\sqrt{m_1m_2(1 - m_1)(1 - m_2)}}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17bb93-700e-4bb1-8bae-3e75e2906888",
   "metadata": {},
   "source": [
    "Consider now the following information which will be useful afterwards. The ideia is that these values are similar to what we expect in real life for sensibility and specificity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d66f26-5e8d-4195-bee9-3f63eb054d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2, v1, v2, rho = 0.9, 0.9, 0.01, 0.01, -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ced9f3e-8eaa-4dc2-9fab-f0200243d6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.201013156990748,\n",
       " 0.8989985761829642,\n",
       " 0.8989985761829642,\n",
       " 0.0010027275030035426)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat = ParameterAlpha().mix_solver(m1, m2, v1, v2, rho, lb = 0.001)\n",
    "tuple(alpha_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec15bb88-e19a-48bc-b24b-7ac27ea929ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.645046339762947,\n",
       " 2.2171031119350904,\n",
       " 2.2171031019177856,\n",
       " 9.809568232079225e-08)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat_2 = ParameterAlpha().minimizer(m1, m2, v1, v2, rho)\n",
    "tuple(alpha_hat_2.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c111aaa-94db-4753-851a-47559e4d753f",
   "metadata": {},
   "source": [
    "Note that the algorithms produce different results, but "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbf6e2d3-4ca9-4f44-b466-cebc0e7beb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8999999999999999, 0.8999999999999999, 0.008999988266841579, 0.008999988266841579, -0.10987317771541383)\n",
      "(0.8304870118306533, 0.8304870110647606, 0.009998992027047132, 0.009998992063003248, -0.20411269769507853)\n"
     ]
    }
   ],
   "source": [
    "print(moments_calculus(alpha_hat))\n",
    "print(moments_calculus(alpha_hat_2.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64ab94-8ef7-4772-8e15-f0fbf76c8a67",
   "metadata": {},
   "source": [
    "Both algorithms outperformed $\\rho$ parameter. It happens because this system has solution $\\alpha_4 < 0$. In that case, $\\rho$ can be even smaller and reaches the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418a4593-3fa6-464e-a602-a40dd2bb2e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This system does not have a solution since alpha_4 < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-848a1ddb02c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mParameterAlpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_equations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/rds-bayesian-analysis/notebooks_book/../scripts/utilits.py\u001b[0m in \u001b[0;36msolve_equations\u001b[0;34m(self, m1, m2, v1, v2, rho)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malpha4\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This system does not have a solution since alpha_4 < 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# finds alpha1,alpha2,alpha3 as function of alpha4, m1, m2, and v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: This system does not have a solution since alpha_4 < 0"
     ]
    }
   ],
   "source": [
    "ParameterAlpha().solve_equations(m1, m2, v1, v2, rho)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ed45aeb2f80697313442a6637689c7cea9f5cd323e50e2056a37945d13c6921"
  },
  "kernelspec": {
   "display_name": "tcc-emap",
   "language": "python",
   "name": "tcc-emap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
