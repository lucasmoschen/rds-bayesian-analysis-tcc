{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e650973-4fd0-4005-8433-bb6809e6b319",
   "metadata": {},
   "source": [
    "# Different prior approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1450ad28-59d1-44cd-9ad2-7a5f453eef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan as ps\n",
    "import stan_utility\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from utilits import ParameterAlpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af926931-9e9b-4dae-a94a-083e00b247c0",
   "metadata": {},
   "source": [
    "## The stan models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa02e70-beb6-4fac-a35a-a8eab01a215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_6f87d4736359dff09d821daa83abc844 NOW.\n"
     ]
    }
   ],
   "source": [
    "compiled = True        \n",
    "model = '../models/sensitivity_specificity/spec_sens_model_logit_normal'\n",
    "if compiled: sm_ln = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_ln = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_ln, f)\n",
    "\n",
    "compiled = True\n",
    "model = '../models/sensitivity_specificity/spec_sens_model_constant_alpha_smooth'\n",
    "if compiled: sm_cbb = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_cbb = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_cbb, f)\n",
    "        \n",
    "compiled = True\n",
    "model = '../models/sensitivity_specificity/spec_sens_model_random_alpha_smooth'\n",
    "if compiled: sm_rbb = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_rbb = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_rbb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8485c-8c3a-462f-a383-63d0b86d09f6",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a11259e-0069-47f1-8c2f-fd06384f1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(ro): \n",
    "    \n",
    "    sens = ro.beta(100, 0.15/0.85 * 100) \n",
    "    spec = ro.beta(100, 0.2/0.8 * 100)\n",
    "    n_neg = ro.poisson(50)\n",
    "    n_pos = ro.poisson(50)\n",
    "    y_pos = ro.binomial(n_pos, sens)\n",
    "    y_neg = ro.binomial(n_neg, spec)\n",
    "    \n",
    "    return sens, spec, n_neg, n_pos, y_pos, y_neg\n",
    "\n",
    "def evaluation(sens_post, spec_post, sens, spec): \n",
    "    \n",
    "    hits = np.zeros(2)\n",
    "    errors = np.zeros(2)\n",
    "    \n",
    "    hdi_sens = az.hdi(sens_post, hdi_prob=.75)\n",
    "    hdi_spec = az.hdi(spec_post, hdi_prob=.75)\n",
    "    if (sens > hdi_sens[0]) & (sens < hdi_sens[1]): \n",
    "        hits[0] += 1\n",
    "    if (spec > hdi_spec[0]) & (spec < hdi_spec[1]): \n",
    "        hits[1] += 1\n",
    "    errors[0] = (sens_post.mean() - sens)**2\n",
    "    errors[1] = (spec_post.mean() - spec)**2\n",
    "    \n",
    "    return hdi_sens, hdi_spec, hits, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0143b18-8745-40b7-8b7d-fa004ca85410",
   "metadata": {},
   "source": [
    "## Wrapper to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed900b7-2f0f-4928-97d9-e8e6dad0e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent_beta_model(n_neg, n_pos, y_pos, y_neg, parameters):\n",
    "    \n",
    "    a_s = parameters['a_s']\n",
    "    b_s = parameters['b_s']\n",
    "    a_e = parameters['a_e']\n",
    "    b_e = parameters['b_e']\n",
    "    sens_post = np.random.beta(a_s + y_pos, b_s + n_pos - y_pos, size=2000)\n",
    "    spec_post = np.random.beta(a_e + y_neg, b_e + n_neg - y_neg, size=2000)\n",
    "    \n",
    "    return evaluation(sens_post, spec_post, sens, spec)\n",
    "\n",
    "def logit_normal_model(n_neg, n_pos, y_pos, y_neg, parameters, stan_model):   \n",
    "\n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'mu_gamma': parameters['mu'], 'Sigma_gamma': parameters['Sigma']}\n",
    "    fit = stan_model.sampling(data=data, iter=4000, control={'max_treedepth': 12})\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "    return evaluation(sens_post, spec_post, sens, spec)\n",
    "\n",
    "def bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, parameters, stan_model): \n",
    "    \n",
    "    m1 = parameters['m1']\n",
    "    m2 = parameters['m2']\n",
    "    v1 = parameters['v1']\n",
    "    v2 = parameters['v2']\n",
    "    rho = parameters['rho']\n",
    "    alpha_hat = np.array(ParameterAlpha().mix_solver(m1, m2, v1, v2, rho))\n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'alpha_data':alpha_hat}\n",
    "    fit = stan_model.sampling(data=data, iter=4000)\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "\n",
    "    return evaluation(sens_post, spec_post, sens, spec), alpha_hat\n",
    "\n",
    "def bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, parameters, alpha_hat, stan_model): \n",
    "    \n",
    "    b = alpha_hat / parameters['var_alpha']\n",
    "    a = alpha_hat * b \n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'a':a, 'b':b}\n",
    "    fit = stan_model.sampling(data=data, iter=4000, control = {'adapt_delta': 0.9})\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "\n",
    "    return evaluation(sens_post, spec_post, sens, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e3db2-2c1d-4356-a5e6-d2fa8b7aa537",
   "metadata": {},
   "source": [
    "## Vague information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bac329-25eb-49e4-a7c7-13e7589682b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    independent_beta={'a_s': 1, 'b_s': 1, 'a_e': 1, 'b_e': 1}\n",
    "    logit_normal={'mu': [0,0], 'Sigma': 4*np.eye(2)}\n",
    "    bivariate_beta={'m1': 0.5, 'm2': 0.5, 'v1': 0.08, 'v2': 0.08, 'rho': 0, \n",
    "                    'var_alpha': np.array([1,1,1,1])}\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-vague-information.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a7073-4f68-47e0-bec7-8d254a93a188",
   "metadata": {},
   "source": [
    "## Information about means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b562ec-a424-4f6c-a8ac-33c8af9813c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276a5bf6a44042e2ac9236b57ea5c451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:3 of 8000 iterations saturated the maximum tree depth of 12 (0.0375 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations ended with a divergence (0.0125 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:130 of 8000 iterations ended with a divergence (1.62 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:3 of 8000 iterations saturated the maximum tree depth of 12 (0.0375 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:141 of 8000 iterations ended with a divergence (1.76 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:131 of 8000 iterations ended with a divergence (1.64 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:2 of 8000 iterations saturated the maximum tree depth of 12 (0.025 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:2 of 8000 iterations saturated the maximum tree depth of 12 (0.025 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n"
     ]
    }
   ],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "independent_beta={'a_s': 5, 'b_s': 0.15/0.85 * 5, 'a_e': 5, 'b_e': 0.2/0.8 *5}\n",
    "logit_normal={'mu': [2.8, 2.25], 'Sigma': 4*np.eye(2)}\n",
    "bivariate_beta={'m1': 0.85, 'm2': 0.8, 'v1': 0.02, 'v2': 0.02, 'rho': 0, \n",
    "                'var_alpha': np.array([1,1,1,1])}\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-mean-information.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb406c-7158-4d93-b4ee-6fbd40998e6e",
   "metadata": {},
   "source": [
    "## Information about means and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2c49bc-48b8-486a-9346-b73cbe82f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c079770de846c099d86195fafd54e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Chain 4: E-BFMI = 0.19\n",
      "WARNING:pystan:E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
      "WARNING:pystan:85 of 8000 iterations ended with a divergence (1.06 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:116 of 8000 iterations ended with a divergence (1.45 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:69 of 8000 iterations ended with a divergence (0.863 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    }
   ],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "independent_beta={'a_s': 5, 'b_s': 0.15/0.85 * 5, 'a_e': 5, 'b_e': 0.2/0.8 *5}\n",
    "logit_normal={'mu': [2.8, 2.25], 'Sigma': np.array([[4, -0.8], [-0.8, 4]])}\n",
    "bivariate_beta={'m1': 0.85, 'm2': 0.8, 'v1': 0.02, 'v2': 0.02, 'rho': -0.2, \n",
    "                'var_alpha': np.array([1,1,1,1])}\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-mean-corr-information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "086aaab4-66a7-4e4c-aa5c-4b35d75b6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-vague-information.csv', index_col=0)\n",
    "df2 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-mean-information.csv', index_col=0)\n",
    "df3 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-mean-corr-information.csv', index_col=0)\n",
    "\n",
    "df1['hits_sens'] = df1.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hits_spec'] = df1.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['errors_sens'] = df1.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['errors_spec'] = df1.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['hdi_sens_lb'] = df1.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hdi_sens_ub'] = df1.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['hdi_spec_lb'] = df1.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hdi_spec_ub'] = df1.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1 = df1.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])\n",
    "\n",
    "df2['hits_sens'] = df2.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hits_spec'] = df2.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['errors_sens'] = df2.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['errors_spec'] = df2.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['hdi_sens_lb'] = df2.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hdi_sens_ub'] = df2.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['hdi_spec_lb'] = df2.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hdi_spec_ub'] = df2.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2 = df2.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])\n",
    "\n",
    "df3['hits_sens'] = df3.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hits_spec'] = df3.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['errors_sens'] = df3.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['errors_spec'] = df3.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['hdi_sens_lb'] = df3.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hdi_sens_ub'] = df3.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['hdi_spec_lb'] = df3.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hdi_spec_ub'] = df3.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3 = df3.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98dd39d8-6a77-4482-a8cd-9569d0ffdea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.788265</td>\n",
       "      <td>0.898020</td>\n",
       "      <td>0.739975</td>\n",
       "      <td>0.862021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.792734</td>\n",
       "      <td>0.899696</td>\n",
       "      <td>0.748013</td>\n",
       "      <td>0.866589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.789246</td>\n",
       "      <td>0.900130</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.859847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.794526</td>\n",
       "      <td>0.904236</td>\n",
       "      <td>0.739859</td>\n",
       "      <td>0.864193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.756      0.755     0.002388     0.002625   \n",
       "bivariate_random        0.749      0.744     0.002264     0.002546   \n",
       "ind_beta                0.738      0.761     0.002531     0.002843   \n",
       "logit_normal            0.741      0.745     0.002405     0.002811   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.788265     0.898020     0.739975     0.862021  \n",
       "bivariate_random       0.792734     0.899696     0.748013     0.866589  \n",
       "ind_beta               0.789246     0.900130     0.735210     0.859847  \n",
       "logit_normal           0.794526     0.904236     0.739859     0.864193  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_grouped = df1.groupby('simulation').mean()\n",
    "df1_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62f95c77-3616-432d-96f0-930b247778ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.805747</td>\n",
       "      <td>0.908645</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.866820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.797803</td>\n",
       "      <td>0.904222</td>\n",
       "      <td>0.744944</td>\n",
       "      <td>0.864393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.806542</td>\n",
       "      <td>0.909443</td>\n",
       "      <td>0.749720</td>\n",
       "      <td>0.867123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.810880</td>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.752838</td>\n",
       "      <td>0.873922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.752      0.750     0.001952     0.002316   \n",
       "bivariate_random        0.747      0.748     0.002167     0.002454   \n",
       "ind_beta                0.741      0.736     0.002009     0.002363   \n",
       "logit_normal            0.699      0.712     0.002300     0.002797   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.805747     0.908645     0.749375     0.866820  \n",
       "bivariate_random       0.797803     0.904222     0.744944     0.864393  \n",
       "ind_beta               0.806542     0.909443     0.749720     0.867123  \n",
       "logit_normal           0.810880     0.915287     0.752838     0.873922  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_grouped = df2.groupby('simulation').mean()\n",
    "df2_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a334f498-7153-478b-ad59-b82cc5c6a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.805547</td>\n",
       "      <td>0.909015</td>\n",
       "      <td>0.748608</td>\n",
       "      <td>0.866570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.795936</td>\n",
       "      <td>0.903484</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.862734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.806450</td>\n",
       "      <td>0.909415</td>\n",
       "      <td>0.749895</td>\n",
       "      <td>0.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.812067</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.753844</td>\n",
       "      <td>0.874486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.743      0.749     0.001989     0.002364   \n",
       "bivariate_random        0.745      0.755     0.002229     0.002504   \n",
       "ind_beta                0.743      0.742     0.002007     0.002365   \n",
       "logit_normal            0.684      0.715     0.002303     0.002804   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.805547     0.909015     0.748608     0.866570  \n",
       "bivariate_random       0.795936     0.903484     0.742036     0.862734  \n",
       "ind_beta               0.806450     0.909415     0.749895     0.867188  \n",
       "logit_normal           0.812067     0.915993     0.753844     0.874486  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_grouped = df3.groupby('simulation').mean()\n",
    "df3_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "758f4897-4b51-456f-9389-7bcec3f482e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAFVCAYAAACqxIpvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABCo0lEQVR4nO3de1xUdf7H8TcMIKh4AQFBNJPMyEu63hMz72Sgtnlp0awsrCztYpZaKVS6alqrVlqWpktZ2m9XgwxNu5hppmZpUe1meEdQEC8IzgDn9wc5G4owJnBm4PV8PHw8HM53zvmemfmcec93vnOOm2EYhgAAAABUKnezOwAAAABURwRxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEHmZ3wFEnTuSosJAzLVYWf//aysw8Y3Y3AFQA6huo2qjxP8/d3U3169eqtO05FMRTU1M1adIkZWdnq169epo1a5aaNm1arM2xY8c0depUHTp0SPn5+XrggQc0aNAgSdKrr76qtWvXymKxyMPDQ4899pi6d+9+WR0tLDQI4pWMxxuouqhvoGqjxl2DQ0F82rRpiomJ0aBBg7RmzRpNnTpVy5cvL9Zm5syZatWqlRYuXKisrCz99a9/VadOnRQcHKw2bdpo9OjR8vHx0c8//6yRI0dq8+bN8vb2rpCdAgAAAJxdmXPEMzMzlZKSoqioKElSVFSUUlJSlJWVVazdzz//bB/l9vPz03XXXaePP/5YktS9e3f5+PhIklq0aCHDMJSdnV2e+wEAAAC4lDJHxNPS0hQUFCSLxSJJslgsCgwMVFpamvz8/OztWrZsqbVr16p169Y6dOiQdu3apdDQ0IvWt3r1ajVp0kQNGza8rI76+9e+rPa4cgEBvmZ3AUAFob6Bqo0adw3l9mPNSZMmacaMGRo0aJBCQkLUpUsXeXgUX/0333yjefPmacmSJZe9/szMM8x3qkQBAb46duy02d0AUAGob6Bqo8b/PHd3t0od/C0ziAcHBys9PV0FBQWyWCwqKChQRkaGgoODi7Xz8/PTnDlz7LdjY2MVFhZmv71r1y5NnDhRr732mpo1a1aOuwAAAAC4njLniPv7+ys8PFxJSUmSpKSkJIWHhxebliJJJ06cUH5+viRp69at+s9//mOfV75792499thjmj9/vlq2bFne+wAAAAC4HDfDMMqc77F3715NmjRJp06dUp06dTRr1iw1a9ZMsbGxGj9+vFq3bq0vvvhC06dPl7u7u+rXr6+pU6cqPDxcknT77bfr8OHDCgoKsq9z9uzZatGihcMdZWpK5eJrLaDqor6Bqo0a//Mqe2qKQ0HcGRDEKxdFDFRd1DdQtVHjf15lB3EucQ8AAACYwGUucQ8AAICq693E2ZKkrJPpkiS/ukVTmmOinzStTxWNIA4AcBnV8Y0aqG6yso9K+l99V2UEcQCAy6lOb9RAdXH+A/X5D9zV4QM2QRwA4DKq4xs1gKqLH2sCAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACbggj4AgBLtmld0GfmzGTZJUs1AT0lSu0e4miXg6qhv50AQBwCU6sI3asBZTZjwhSTp0KEzkqTQ0NqSpLlze5jWJ2dHfZuLIA6gWuGN2nHnR8bOj5wxUgZXcfDgaUn/q29cjPp2DgRxANUSb9RA1XP+A/X5D9x8wIazI4gDqFZ4owYAOAvOmgIAAACYgCAOAAAAmIAgDgAAAJiAIA4AAACYgCAOAAAAmICzpqBKeTdxtiQp62TReVH96hadFzUm+knT+gSUZcuE8ZKknEMHJUm1QhtLkm6cO9+0PgEAKh5BHFVSVvZRSf8L4oArOHOweBAHAFRtBHFUKedHvs+PjDMSDldwfuT7/Mg4I+FA1cK3XrgUgjgAAEAl4FsvXIggDgAAUIH41guXwllTAAAAABM4FMRTU1M1fPhw9e/fX8OHD9e+ffsuanPs2DE9+OCDio6O1i233KI1a9bYlxUUFCg+Pl59+vRR3759tWrVqnLbAQAAAMAVORTEp02bppiYGK1bt04xMTGaOnXqRW1mzpypVq1aKTExUe+8845efvllpaWlSZISExN14MABrV+/Xu+//74WLFigQ4cOle+eAAAAAC6kzCCemZmplJQURUVFSZKioqKUkpKirKysYu1+/vlnde/eXZLk5+en6667Th9//LEkae3atRo6dKjc3d3l5+enPn36KDk5ubz3BZVs17x07ZqXrq+ePqSvnj5kvw0AAICylfljzbS0NAUFBclisUiSLBaLAgMDlZaWJj8/P3u7li1bau3atWrdurUOHTqkXbt2KTQ01L6OkJAQe9vg4GAdPXq0vPelSnPmUx+dzbBJkmoGeprcEwAAANdRbmdNmTRpkmbMmKFBgwYpJCREXbp0kYdH+Z2Uxd+/drmtyxX5eBeF3My0w5KkBtc0kyQFBPhW2DbLWne/F4qWb3phvyTppmeuqrC+XC7v3x+vinx84Nq8vb0kOddrxKcSX7eXsw1v76zLvk9Fo8ZRGmesb8k5a5z6NleZSTk4OFjp6ekqKCiQxWJRQUGBMjIyFBwcXKydn5+f5syZY78dGxursLAw+zqOHDmiNm3aSLp4hNwRmZlnVFhoXNZ9qpJ20+dKknJ/Hxk/f/vYsdMVsr2AAF+H152XZ6vQvvwZztgnOJe8PKsk53qN5FbS6/Zy6ltyznpyxj7BeThjfUvOWePOWEtm9snd3a1SB3/LDOL+/v4KDw9XUlKSBg0apKSkJIWHhxebliJJJ06ckK+vrzw8PLR161b95z//0fz5RdMmIiMjtWrVKvXr10/Z2dnasGGD3nnnnYrZo3IwYcIXkqRDh85IkkJDi56QuXN7mNYnAAAAVC0OzR2Ji4vTpEmT9Nprr6lOnTqaNWuWpKJR7/Hjx6t169bavXu3pk+fLnd3d9WvX1+LFi2Sj4+PJGnQoEH6/vvv1a9fP0nSQw89pMaNnf+qUgcPFn0SOx/EAQAAgPLiUBAPCwsr8dzfixcvtv+/R48e6tGj5BFji8Wi+Pj4P9nFynd+5Pv8yDgj4QAAAChvXFkTAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwAUEcAAAAMAFBHAAAADABQRwAAAAwgYcjjVJTUzVp0iRlZ2erXr16mjVrlpo2bVqsTWZmpiZPnqy0tDTZbDZ16dJFzzzzjDw8PEpdBgAAAFRHDo2IT5s2TTExMVq3bp1iYmI0derUi9osWrRIYWFhSkxMVGJion788UetX7++zGUAAABAdVRmEM/MzFRKSoqioqIkSVFRUUpJSVFWVlaxdm5ubsrJyVFhYaGsVqtsNpuCgoLKXAYAAABUR2XODUlLS1NQUJAsFoskyWKxKDAwUGlpafLz87O3Gzt2rMaNG6eIiAjl5uZqxIgRat++fZnLHOXvX/uy2pcHb28vSVJAgG+lb/tSfLw9JVVOnxzdhrd31mW1rwzelfg4wTVR345vgxqHq3HG+pacs8apb3OV2yTt5ORktWjRQsuWLVNOTo5iY2OVnJysyMjIUpc5KjPzjAoLjfLqrkPy8qySpGPHTlfqdkuTm2eTVPF9CgjwdXgbeZXUp8vhjH2Cc6G+Hd+GM9aTM/YJzsMZ61tyzhp3xloys0/u7m6VOvhb5tSU4OBgpaenq6CgQJJUUFCgjIwMBQcHF2uXkJCggQMHyt3dXb6+vurVq5e2bdtW5jIAAACgOioziPv7+ys8PFxJSUmSpKSkJIWHhxebliJJoaGh2rRpkyTJarVq69atat68eZnLAAAAgOrIobOmxMXFKSEhQf3791dCQoLi4+MlSbGxsdqzZ48kacqUKdq5c6eio6M1ePBgNW3aVMOGDStzGQAAAFAdOTRHPCwsTKtWrbro74sXL7b/v0mTJlq6dGmJ9y9tGQAAAFAdcWVNAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAACYLjX1Nz355GNa8d47+uc/31azZo305JOPKTX1N7O7VmEI4gAAADDVxo3rdfPNNyohYbnybTZJ0pkzp5WQsFw333yjNm5cb3IPKwZBHADgMqrjiBlQ1aWm/qbRo0cpN/es8vNtxZbl59uUm3tWo0ePqpJ1ThAHALiE6jpiBlR1CxcukM1mK7WNzWbT66+/Wkk9qjwEcQCA06vOI2ZAVffBBysvqusL5efbtGrVe5XUo8pDEAcAOL3qPGIGVHU5OWccanfmjGPtXAlBHADg9KrziBlQ1dWqVduhdrVrO9bOlRDEAQBOrzqPmAFV3ZAhw+Th4VlqGw8PTw0dekcl9ajyEMQBAE6vOo+YAVXdgw+Ok6dn6UHc09NT99//UCX1qPIQxAEATq86j5gBVd3VVzfTkiXL5eNT86I69/DwlI9PTS1ZslxXX93MpB5WHIeCeGpqqoYPH67+/ftr+PDh2rdv30VtMjMzNWbMGEVHRysyMlJxcXHKz8+3L1+7dq2io6MVFRWl6OhoHT9+vNx2AgBQtVXnETOgOujdu58+/3yLRo26217rvr6+GjXqbn3++Rb17t3P5B5WDA9HGk2bNk0xMTEaNGiQ1qxZo6lTp2r58uXF2ixatEhhYWF64403ZLPZFBMTo/Xr12vAgAHas2ePXnnlFS1btkwBAQE6ffq0vLy8KmSHAABVz/kRs9GjR1109hQPD095enpW2REzoLq4+upmmjlzrt5NnC1Jiln5pMk9qnhljohnZmYqJSVFUVFRkqSoqCilpKQoKyurWDs3Nzfl5OSosLBQVqtVNptNQUFBkqS3335bo0ePVkBAgKSiTzg1atQo730BAJQj+1UsVzjHVSyr64gZUBGcrb6rqzJHxNPS0hQUFCSLxSJJslgsCgwMVFpamvz8/Oztxo4dq3HjxikiIkK5ubkaMWKE2rdvL0nau3evQkNDNWLECJ09e1Z9+/bVgw8+KDc3N4c76u9f+T/A8fYuGrUPCPCt9G1fio930ZtPZfTJ0W14e2ddVvvK4F2JjxNcy969ezV37ly9994J2Wz5Wr06RiNHjtSECRMUFhZmat+cqb4//vhjDRkyRDabTcODJ0oquorlO+8s18qVK/TBBx/olltuqfB+Xigg4AZ16vSGXn/3OUnS/Z9NrfQ+wHk5c31LzlPjzlrf51Wn93CHpqY4Ijk5WS1atNCyZcuUk5Oj2NhYJScnKzIyUgUFBfrll1+0dOlSWa1W3XfffQoJCdHgwYMdXn9m5hkVFhrl1V2H5OVZJUnHjp2u1O2WJjev6CvZiu5TQICvw9vIq6Q+XQ5n7BPMt3HjevvUhvz8gZKk06dPa/HiN/X228u0ZMlyU0dVnaW+U1N/0+23D1Fu7tmLltlsNtlsNt1++xB9/vkW06aCUOO4kLPXt+QcNU59l87d3a1SB3/LnJoSHBys9PR0FRQUSJIKCgqUkZGh4ODgYu0SEhI0cOBAubu7y9fXV7169dK2bdskSSEhIYqMjJSXl5dq166t3r17a/fu3RWwOwBQMi6R7jiuYglXQ307jvp2LmUGcX9/f4WHhyspKUmSlJSUpPDw8GLTUiQpNDRUmzZtkiRZrVZt3bpVzZs3l1Q0r3zz5s0yDEM2m01ff/21rrvuuvLeFwC4JN58HMdVLOFqqG/HUd/OxaHTF8bFxSkhIUH9+/dXQkKC4uPjJUmxsbHas2ePJGnKlCnauXOnoqOjNXjwYDVt2lTDhg2TJN16663y9/fXgAEDNHjwYF1zzTUaMmRIBe0SAFyMNx/HcRVLuBrq23HUt3NxaI54WFiYVq1addHfFy9ebP9/kyZNtHTp0hLv7+7ursmTJ2vy5Ml/spsAcGV483FcrVq1deZM2XMzuYolnAX17Tjq27lwZU0A1QKXSHccV7GEq6G+HUd9OxeCOIBqgTcfx3EVS7ga6ttx1LdzIYgDqBZ483Hc+atY+vjUvCjceHh4ysenJlexhFOhvh1HfTsXgjiAaoE3n8tT/CqWXpLcuIolnBb1fXmob+dRbhf0AQBnd/7N5/XXX9U//3laNlu+fH19NXToHbr//od4k77A1Vc308yZc7VrXrok6aVHnjK5R8ClUd+Xh/p2DgRxANXK+Tcfm+0LSdLcuUtM7hGA8kJ9w9UwNQUATJaa+puefPIxvbfiHSX88201a9ZITz75GFcBBIAqjiAOACbauHG9br75RiUkLJct3yZD0pkzp5WQsFw333yjNm5cb3YXAQAVhCAOACZJTf1No0ePUm7u2YuuCpifb1Nu7lmNHj2KkXEAqKII4qhSzn/Fv+K9d/RPvuKHk1u4cIFsttIvy22z2fT6669WUo8AVASmn+FSCOKoMv74FX/+7+GGr/jhzD74YOVFI+EXys+3adWq9yqpRwDKG9PPUBqCOKoEvuKHK8rJOeNQuzNnHGsHwLnw3oSyEMRRJfAVP1xRrVq1HWpXu7Zj7QA4F96bUBaCOKoEvuKHKxoyZNhFVwG8kIeHp4YOvaOSegSgPPHehLIQxFEl8BU/XNGDD46Tp2fpQdzT01P33/9QJfUIQHnivQllIYijSuArfriiq69upiVLlsvHp+ZFI+MeHp7y8ampJUuWc2luwEXx3oSyEMRdBKc+Kh1f8cNV9e7dT59/vkWjRt0tT09PuUny9fXVqFF36/PPt6h3735mdxHAn8R7E8pCEHcBnPqobHzFD1d29dXNNHPmXN1xxwiNvPNu7d17WDNnzmUkHHBxvDehLARxJ8epjxzDV/wAAGfDexPKQhB3cs586iP7VSxXOMdVLC/8il/iK34AgLmYfobSeJjdAZTuck59NHPm3ErqVdF0mdGjR8lms+mOkImS/jdd5v33V2jJkuWmHFzOf8X/buJsSVLMyicrvQ8AAPzR+femLb8PrL02d77JPYKzYETcyTnjqY+YLgMAAHDlCOIlKD7lYpmpUy6c8dRHzjxdBgAAwFUQxC/wxzOUFI32GqaeocQZT33ElcIAAACuHEH8D5xxyoUznvrIGafLAAAAuBqC+B8445QLZzz1kTNOlwEAAHA1BPE/cNYpF8526iNnnC4DAADgajh94R8485QLZzr10YMPjtP7768o9UMLVwoDAAAoHSPif8CUC8c443QZAAAAV0MQ/wOmXDiu+HQZL0luXCkMAADgMjg0NSU1NVWTJk1Sdna26tWrp1mzZqlp06bF2mRmZmry5MlKS0uTzWZTly5d9Mwzz8jD43+b+O2333TbbbcpJiZGTz31VLnuSHlgysXlOT9dZte8dEnSS48433MKAADgrBwaEZ82bZpiYmK0bt06xcTEaOrUqRe1WbRokcLCwpSYmKjExET9+OOPWr/+f+fcLigo0LRp09SnT5/y6305Y8oFAAAAKkuZQTwzM1MpKSmKioqSJEVFRSklJUVZWVnF2rm5uSknJ0eFhYWyWq2y2WwKCgqyL3/jjTd08803XzSS7mwuPEMJUy4AAABQEcqcmpKWlqagoCBZLBZJksViUWBgoNLS0uTn52dvN3bsWI0bN04RERHKzc3ViBEj1L59e0nSzz//rM2bN2v58uV67bXX/lRH/f0r7weSAQE3qFOnN2SxFI3ov/HGqkrbdll8vItG6gMCfCt8W45uw9s767LaVwbvSnyc4Jq8vb0kOddrxBnrW6LG4Xqcsb4l56xx6ttc5Xb6wuTkZLVo0ULLli1TTk6OYmNjlZycrN69e+vZZ5/V3//+d3uY/zMyM8+osNAor+46JC/PKkk6dux0pW63NLl5RfPXK7pPAQG+Dm8jr5L6dDmcsU9wLtS349twxnpyxj7BeThjfUvOWePOWEtm9snd3a1SB3/LDOLBwcFKT09XQUGBLBaLCgoKlJGRoeDg4GLtEhISNGPGDLm7u8vX11e9evXStm3b1KZNGx04cEBjxoyRJJ06dUqGYejMmTN6/vnnK2avAAAAACdXZhD39/dXeHi4kpKSNGjQICUlJSk8PLzYtBRJCg0N1aZNm9SmTRtZrVZt3bpVffv2VUhIiLZt22Zvt2DBAp09e9Ypz5oCAAAAVBaHzpoSFxenhIQE9e/fXwkJCYqPj5ckxcbGas+ePZKkKVOmaOfOnYqOjtbgwYPVtGlTDRs2rOJ6DgAAALgwh+aIh4WFadWqi3+wuHjxYvv/mzRpoqVLl5a5rnHjxl1G9wAAAICqiStrAgAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAmIIgDAAAAJiCIAwAAACYgiAMAAAAm8HCkUWpqqiZNmqTs7GzVq1dPs2bNUtOmTYu1yczM1OTJk5WWliabzaYuXbromWeekYeHh1599VWtXbtWFotFHh4eeuyxx9S9e/eK2B8AAADAJTg0Ij5t2jTFxMRo3bp1iomJ0dSpUy9qs2jRIoWFhSkxMVGJiYn68ccftX79eklSmzZt9MEHH+jDDz/UjBkz9NhjjykvL6989wQAAABwIWUG8czMTKWkpCgqKkqSFBUVpZSUFGVlZRVr5+bmppycHBUWFspqtcpmsykoKEiS1L17d/n4+EiSWrRoIcMwlJ2dXc67AgAAALiOMqempKWlKSgoSBaLRZJksVgUGBiotLQ0+fn52duNHTtW48aNU0REhHJzczVixAi1b9/+ovWtXr1aTZo0UcOGDS+ro/7+tS+rfXnw9vaSJAUE+Fb6ti/Fx9tTUuX0ydFteHtnXVb7yuBdiY8TXBP17fg2qHG4Gmesb8k5a5z6NpdDc8QdkZycrBYtWmjZsmXKyclRbGyskpOTFRkZaW/zzTffaN68eVqyZMllrz8z84wKC43y6q5D8vKskqRjx05X6nZLk5tnk1TxfQoI8HV4G3mV1KfL4Yx9gnOhvh3fhjPWkzP2Cc7DGetbcs4ad8ZaMrNP7u5ulTr4W+bUlODgYKWnp6ugoECSVFBQoIyMDAUHBxdrl5CQoIEDB8rd3V2+vr7q1auXtm3bZl++a9cuTZw4Ua+++qqaNWtWzrsBAAAAuJYyg7i/v7/Cw8OVlJQkSUpKSlJ4eHixaSmSFBoaqk2bNkmSrFartm7dqubNm0uSdu/erccee0zz589Xy5Yty3sfAAAAAJfj0FlT4uLilJCQoP79+yshIUHx8fGSpNjYWO3Zs0eSNGXKFO3cuVPR0dEaPHiwmjZtqmHDhkmS4uPjlZeXp6lTp2rQoEEaNGiQfvnllwraJQAAAMD5OTRHPCwsTKtWrbro74sXL7b/v0mTJlq6dGmJ9/+///u/P9k9AAAAoGriypoAAACACQjiAAAAgAkI4gAAAIAJCOIAAACACQjiAAAAgAkI4gAAAIAJCOIAAACACQjiAAAAgAkI4gAAAIAJHLqyJgAAAFCR3k2cLUn6df/3xW7HRD9pWp8qGkEcAAAATsOvXkOzu1BpCOIAAJdRHUfMgOqiOtYxQRwA4HKq04gZgKqLIA4AcBnVccQMQNXFWVMAAAAAExDEAQAAABMQxAEAAAATEMQBAAAAExDEAQAAABNw1hQAQIl2zUuXJB3/4Wyx2+0eCTKtTwDKB/XtHAjiAIBS1Qz0NLsLACoI9W0ugjiAamXChC8kSVu3phW7PXduD9P65KwYGYOrob4dR307B4I4gGqpcWNfs7sAoIJQ33AVBHEA1QojY0DVRX3D1XDWFAAAAMAEBHEAAADABARxAAAAwAQEcQAAAMAEBHEAAADABARxAAAAwAQOBfHU1FQNHz5c/fv31/Dhw7Vv376L2mRmZmrMmDGKjo5WZGSk4uLilJ+fL0kqKChQfHy8+vTpo759+2rVqlXluhMAAACAq3EoiE+bNk0xMTFat26dYmJiNHXq1IvaLFq0SGFhYUpMTFRiYqJ+/PFHrV+/XpKUmJioAwcOaP369Xr//fe1YMECHTp0qHz3BAAAAHAhZQbxzMxMpaSkKCoqSpIUFRWllJQUZWVlFWvn5uamnJwcFRYWymq1ymazKSio6PKpa9eu1dChQ+Xu7i4/Pz/16dNHycnJFbA7AAAAgGso88qaaWlpCgoKksVikSRZLBYFBgYqLS1Nfn5+9nZjx47VuHHjFBERodzcXI0YMULt27e3ryMkJMTeNjg4WEePHr2sjvr7176s9uXB29tLkhQQ4DyXyvXx9pRUOX1ydBve3lmX1b4yeFfi4wSUF2esbwDlhxrHhcrtEvfJyclq0aKFli1bppycHMXGxio5OVmRkZHlsv7MzDMqLDTKZV2OysuzSpKOHTtdqdstTW6eTVLF9ykgwNfhbeRVUp8uhzP2CSiLM9Y3gPJDjTs/d3e3Sh38LXNqSnBwsNLT01VQUCCp6IeXGRkZCg4OLtYuISFBAwcOlLu7u3x9fdWrVy9t27bNvo4jR47Y26alpalhw4bluR8AAACASykziPv7+ys8PFxJSUmSpKSkJIWHhxebliJJoaGh2rRpkyTJarVq69atat68uSQpMjJSq1atUmFhobKysrRhwwb179+/vPcFAFzSlgnjtWXCeKVv3aL0rVvstwEAVZtDZ02Ji4tTQkKC+vfvr4SEBMXHx0uSYmNjtWfPHknSlClTtHPnTkVHR2vw4MFq2rSphg0bJkkaNGiQQkND1a9fPw0bNkwPPfSQGjduXEG7BACuqXbjxqrNsREAqg2H5oiHhYWVeO7vxYsX2//fpEkTLV26tMT7WywWe3gHABR349z5ZncBAGACrqwJAAAAmKDczpoCAACAi53/zUf61i3FbvNtGAjiAAAAlYDfgOBCBHEAAIAKxMg3LoUgjirl3cTZkqRf939f7HZM9JOm9QkAAKAkBHFUSX71uGAUAABwbgRxVCmMfAMAAFdBEHcR/OIaAACgaiGIuxh+cQ0AAFA1EMRdBCPfAAAAVQtX1gQAAABMQBAHAAAATEAQBwAAAExAEAcAAABMwI818aftmpcuSTr+w9lit9s9EmRanwAAAFwFQRxXrGagp9ldAAAAcDkE8RJMmPCFJGnr1rRit+fO7WFan5wRI98AAAB/HkG8FI0b+5rdBQAAAFRRBPESMPINAACAisZZUwAAAAATEMQBAAAAExDEAQAAABMQxAEAAAATEMQBAAAAExDEAQAAABMQxAEAAAATEMQBAAAAExDEAQAAABO4zJU13d3dzO5CtcNjDlRd1DdQtVHjf05lP25uhmEYlbpFAAAAAExNAQAAAMxAEAcAAABMQBAHAAAATEAQBwAAAExAEAcAAABMQBAHAAAATEAQBwAAAExAEAcAAABMQBAHAAAATEAQBwAAAExAEEeFufXWW7Vt2zazuwFUOc5UW0eOHFG7du1UUFBwyTYtWrTQ/v37K7FXQPmh3lyfMz8mBHGT3XvvvZo3b95Ff9+wYYO6deum/Px8E3pVPj766CN17tzZ7G6gGtqxY4fuuOMOtW/fXp06ddIdd9yh3bt3S5L+9a9/6W9/+5vJPbwyzlRbISEh2rVrlywWiyTpzjvv1KpVq0zuFSoT9VZ5qLeqhyBusttuu01r1qyRYRjF/v7hhx8qOjpaHh4eJvXsz7vSDw+u/OED5jtz5oweeOABjRw5Ut988402bdqkhx9+WF5eXg6vo7TRJjNRW3A21FvF3R+uo6Tn2tHnnyBusj59+ujkyZPasWOH/W8nT57UZ599psGDB2v37t0aPny4OnTooIiICD333HOyWq32tps3b1b//v3Vvn17xcXFaeTIkfZPxwsWLNATTzxhb3vo0CG1aNHC/uI4ffq0pkyZooiICHXv3l0vv/zyJQ+ICxYs0Pjx4/Xoo4+qXbt2uu222/Tzzz/bl/fq1UtvvPGGoqOj1bZtW+Xn56tXr17asmWLJMlqtWr69OmKiIhQRESEpk+fbt+Pbdu26aabbtIbb7yhbt26afLkycrKytL999+vDh06qFOnToqJiVFhYWE5PeqoylJTUyVJUVFRslgs8vb2VkREhK677jrt3btX06ZN03fffad27dqpQ4cOkqRJkyZp2rRpio2NVdu2bbVt2zbt3btXd955pzp06KBbb71VGzdutG9j0qRJio+P15gxY9SuXTsNHTpUBw4csC8vrS4v5Ky1NX/+fD3//POSJJvNprZt22r27NmSpLy8PLVu3VonT54sdlx5+eWXtWPHDj333HNq166dnnvuOfv6tmzZon79+qljx46Kj4+/aPDhwsfjiSeeULt27RQdHa3U1FS9/vrr6tq1q3r06KHNmzfb25d2HDtw4IBGjRqlzp07q3PnzpowYYJOnTpV7LF96623FB0drfbt2+vRRx/VuXPnSuwXSka9UW8VUW9Xuq4333zT/hx98MEHJW7jvOzsbE2ePFkRERHq2LGjxo4da1+2cuVK9e3bV506ddIDDzyg9PR0+7IWLVronXfeUb9+/dSvX78Sn3+HGDDd008/bUyZMsV+e8WKFcbAgQMNwzCMPXv2GLt27TJsNptx8OBBIzIy0li6dKlhGIaRmZlptGvXzli3bp1hs9mMt99+27j++uuNlStXGoZhGPPnzzcmTJhgX+/BgweNa6+91rDZbIZhGMaDDz5oPPvss0ZOTo5x/Phx4/bbbzdWrFhRYh/nz59vXH/99cbHH39sWK1W48033zR69uxpWK1WwzAMo2fPnsbAgQONI0eOGLm5ufa/ffXVV4ZhGMY//vEPY+jQocbx48eNzMxMY/jw4cbLL79sGIZhfP3110Z4eLgxe/Zs49y5c0Zubq4xZ84c49lnnzWsVqthtVqN7du3G4WFheX0iKMqO336tNGpUyfjySefND7//HMjOzu72PL/+7//M+64445if3vqqaeMv/zlL8aOHTuMgoIC4/Tp00afPn2MhQsXGufOnTO2bNlitG3b1ti7d6+9fceOHY3vv//esNlsxuOPP248+uijhmGUXZcXctba2rJlixEVFWUYhmHs3LnT6N27tzFkyBD7sujoaMMwLj6ujBw58qJ9vfbaa40xY8YYJ0+eNA4fPmx07tzZ+OKLLy75eLRq1crYtGmTYbPZjIkTJxo9e/Y0XnvtNcNqtRrvv/++0bNnT3v70o5j+/btMzZv3mycO3fOyMzMNGJiYowXXnjBft+ePXsat99+u3H06FHjxIkTRmRkpPHuu++W2C+UjHqj3iqi3q5kXV988YXRtWtX45dffjFycnKMxx9/3Lj22muNffv2lbit2NhY45FHHjGys7MNq9VqbNu2zf64d+rUyfjhhx+Mc+fOGc8995wRExNT7HG+++67jRMnThi5ubklPv+OYETcCQwePFjJycnKy8uTJK1evVq33XabJKlVq1Zq27atPDw8FBoaquHDh2v79u2SpE2bNql58+bq16+fPDw8NGrUKDVo0MChbR4/flybNm3SlClTVLNmTfn7++vuu+/WRx99dMn7tGzZUpGRkfL09NQ999wjq9Wq77//3r78zjvvVHBwsLy9vS+6b2Jioh566CH5+/vLz89PDz30kD788EP7cnd3d40fP15eXl7y9vaWh4eHjh07piNHjsjT01MdOnSQm5ubQ/uG6q127dp699135ebmpmeffVZdu3bVAw88oOPHj5d6v969e6t9+/Zyd3fXzz//rLNnz2rMmDHy8vJS165d1bNnz2L10bdvX7Vp00YeHh4aOHCgfvrpJ0l/ri6dsbbatWunffv26cSJE9qxY4eGDBmi9PR05eTkaPv27erUqVOp+3Sh2NhY1alTRyEhIercuXOxUcgLdejQQd27d5eHh4ciIyN14sQJjRkzRp6enhowYIAOHz6sU6dOlXkcu+qqq9StWzd5eXnJz89P99xzj/34+cfHNigoSPXq1VPPnj3tzyMcQ71RbxVRb1eyro8//lh//etfde2116pmzZp6+OGHL7nvGRkZ2rRpk+Lj41W3bl15enraH+vExETdfvvtatmypby8vPT444/ru+++06FDh+z3HzNmjOrVq2d/rVz4/DvC9SYgV0EdOnSQn5+fNm7cqDZt2uiHH37QK6+8Iqnoa7+ZM2fqhx9+UG5urgoKCtSyZUtJRS+ghg0b2tfj5uZW7HZpjhw5ovz8fEVERNj/VlhYqODg4Eve54/rdnd3V1BQkDIyMux/K+2+GRkZCgkJsd8OCQkpdt/69eurRo0a9tv33nuvXnnlFY0ePVqSNHz4cI0ZM8ahfQPCwsI0c+ZMSdLevXs1ceJEzZgxQy+99NIl7/PH1+/52nJ3/99YRUhISLGvJf/4Zu/t7a2zZ88Wu+95jtSlM9aWt7e3WrVqpe3bt2v79u164IEH9NNPP+nbb7/V9u3bNXLkyFL36UIBAQH2//v4+CgnJ+eSbf39/Yv1o379+vYfp51/czt79qwyMjJKPY5lZmbqhRde0I4dO5STkyPDMFSnTp1S+/XHxw6Ood6oN6l86+1K1pWRkaFWrVrZlzVq1OiS+3706FHVrVtXdevWvWhZRkaGPW9JUq1atVSvXj2lp6crNDRU0sWvlQuff0cQxJ3EoEGDtHr1aqWmpqpbt272g05cXJyuv/56zZ07V7Vr19bbb7+tdevWSSp6Ef7xQGUYho4ePWq/7ePjYx9ll1RshKJhw4by8vLS119/7fAPQv+47sLCQqWnpyswMND+t9JGrAMDA3XkyBE1b95ckpSWllbqfWvXrq1JkyZp0qRJ+u9//6tRo0apdevW6tq1q0N9Bc4LCwvTX//6V73//vuSSn+dnhcYGKijR4+qsLDQHg7S0tLUtGnTMu9bVl2WxFlrq1OnTvr666/1008/qXXr1urUqZM2b96s3bt3q2PHjqXuU2Uo6zg2d+5cubm56cMPP1T9+vW1YcOGYvNoUf6oN+qtPOrtStYVGBiotLQ0++0jR45csm3Dhg118uRJnTp16qKgHxgYqMOHD9tvnz17VtnZ2QoKCrL/7cLn+898c8/UFCcxePBgbd26VStXrtTgwYPtf8/JyVGtWrVUq1Yt7d27VytWrLAv69Gjh3755Rdt2LBB+fn5euedd4qF7fDwcG3fvl1HjhzR6dOn9frrr9uXBQYGqlu3bpo5c6bOnDmjwsJCHThwQN98880l+/jjjz9q/fr1ys/P17Jly+Tl5aUbbrjBof279dZbtXDhQmVlZSkrK0uvvvqqoqOjL9n+s88+0/79+2UYhmrXri2LxVJstAS4lL1792rJkiX2N9u0tDQlJSXZX6v+/v5KT08v9qPnC7Vp00Y+Pj568803ZbPZtG3bNn366acaMGBAmdsvqy5L4qy11bFjR61evVphYWHy8vJSp06dtGrVKoWGhsrPz6/E+zRo0EAHDx50qO9XqqzjWE5OjmrWrKk6deooPT1db775ZqX0qzqh3qi3iqi3K1lXZGSk/v3vf+vXX39Vbm6ufYbBpfbppptuUnx8vE6ePCmbzWafAhMdHa1//etf+umnn2S1WvXSSy+pTZs29tHw8kKycRKhoaFq166dcnNz1bt3b/vfn3rqKSUlJekvf/mLnn322WIHJj8/P82bN08vvviiOnfurF9//VWtWrWSp6enJKlbt24aMGCABg4cqL/+9a/q2bNnsW3Onj1bNptNAwYMUMeOHTV+/HgdO3bskn3s3bu31q5dq44dO2rNmjVasGCBfVtlGTt2rFq1aqWBAwdq4MCBatmyZbFfJl9o//79uueee9SuXTsNHz5cf/vb35zmPK5wbrVr19b333+voUOHqm3btho2bJiuvfZaTZo0SZLUpUsXXXPNNYqIiLjka8rLy0sLFy7Upk2b1KVLF8XHx2v27NkKCwsrc/tl1WVJnLW22rVrp3PnztlH46655hrVqFHDfvaLkowaNUrr1q1Tx44d9cILLzi0D1eitOPYww8/rJSUFHXo0EFjxoxRv379Krw/1Q31Rr1VRL1dybp69Oihu+66S3fddZf69u2rLl26lLlPHh4euuWWW3TjjTdq2bJlkqSuXbvqkUce0bhx4xQREaGDBw/q5ZdfdrgfO3bsULt27cps52YYlzinDVxOYWGhbrrpJs2ZM6fMF97lWrBggfbv3685c+aU63qBqq6suqS2gPJDvcHVMCLu4r788kudOnVKVqtVixYtkiS1bdvW3E4B1Rx1CVQe6g2ujB9rurjvvvtOTzzxhKxWq6655hq9+uqrDp8yB0DFoC6BykO9wZUxNQUAAAAwAVNTAAAAABMQxAEAAAATEMQBAAAAExDEAQAAABMQxAEAAAATEMQBAAAAExDEAQAAABMQxAEAAAATcGVNF5GZmanDh4/IZrOa3RUAAFAFeXp6qVGjEPn7+5vdlWqDIO4CMjMzdfDgITVoECwvL2+5ubmZ3SUAAFCFGIYhqzVPBw4cVH5+voKCgszuUrXA1BQXcPjwETVoEKwaNXwI4QAAoNy5ubmpRg0fBQSEaN++/crOPml2l6oFgrgLsNms8vLyNrsbAACgivPy8pbF4q7Vq9eY3ZVqgSDuIhgJBwAAFc3NzU1ubm46duyYbDab2d2p8gjiAAAAKMbNzU2GYZjdjSqPIA5TvfXW63ruuWfLvS3M8+KLM/T222+a3Y1y8fDDY5SYuNrsbjiV8nh+165N1IMP3ltOPUJVwOuqbEOGRGv79m1mdwPljCCOK+YKBwdCfMkq4rmbOHGK7r77PknSt9/u0G23DSjX9aNiDRkSrV69uqlv3+6KjOypiRMfUXr6UfvyPz6/ZnC1sMWxpwivK6BkBHEAVYJhGCosLDS7G1XCrFkv6ZNPvtSaNcmqX99P//jHi2Z3CVVAdXpd5efnm90FuAjOI45ytXZtohITV6tly9ZKSlojX19fPf74U+ratZsk6ciRw5oxI16//PKzWrZspSZNrrqs9Vut5zR16mRt3fqVGjdurMmTp6l582slScePH9PLL8/W99/vko9PTQ0bFqOhQ+/Q119v0T//uVSGYejLLz9XSEioli1boY8++lDvvrtcGRkZqlevvkaMGKXBg28v50fENVmtVi1cuECffvqJJKlXr7568MFx8vLykiS9884yrVz5riQ33XffA5o16wW9996/FRraWNOnxykgIFB33nmPnnjiEdlsVvXt212StGLFv9SgQUCxbU2fHidvbx8dPXpE3323S02bXq24uOlq1ChUkrRnz/eaN2+uDh7cr8aNr9Ijj0xQ69Y3SCqaOtK69Q367rud+uWXX7R8+Xu6447b9PjjT2nlyneVmZmpYcP+pgEDovXcc88qNfU3de7cVVOnPi9PT0+dOnVKL7wwVSkpPyg/v0Bt2tygJ56YrMBAzp8rSTVq1FDPnr01b95L9r+df37HjBmrESOGaOzYR9StW9Hzm5+fr0GD+uull15VixbXlbF2Qy+/PFvJyR/J37+BHn/8KXXo0EmSdObMGS1Y8JK+/vorubm5a8CAaN177/06ePCA5sz5u/Lz89W3b3dZLBYlJ3+uLVs2a/Hi13T48GHVrl1bt946UPfee/8lt/zll5/rrbfe0JEjh1WvXj09/vhT6tLlRh0/fkwvvjhDu3d/rzp16mjEiLs0cOBtkopGtvftS5WXl5c2bfpcQUEN9cwzcbruuuslSQkJb+uDD95XTk6OGjRooAkTJik/P7/EY091VxVfV99+u0PPPz9Vt98+TCtXrlDHjp30yCMTSz2+PPzwGN1wQzt9++12/frrr2rVqrWmTZuuevXqSZKSkz/S4sULlZubq+HDY4ptr7Rj9Pm+DBkyXCtWJMhicdeECZPl6emhefNe0smT2frb30Zq1KjRl/vUoQIQxF3QJ5/sV3LyvgrdRmRkU/Xte3kh+byUlB90yy1R+uijDfrww39r5szntXr1x3Jzc1N8/DNq1aq1XnrpFaWk/KCJEx9V9+49HF73l19+obi46Zo69XmtXLlCU6Y8oRUr/iV3d3c9+eRj6t69h+LiZigjI12PPvqQmjS5Sl263Kg777xHhw8f0tSpz9vXVb++n2bP/odCQhrpu+++1RNPjFd4eEsHDvR/3qFPknUgeW2FrV+SmkQOUGjfyCtax/LlS/Tjj3v09ttFYXvy5AlatuwtxcY+qK+/3qL3339X//jHawoJaaQXX5xe4jp8fHw0Z848Pf/8VP3736Xv84YN6zR37nxde+11mj49Tm+88ari4/+uU6dOauLER/Xoo0+oT5/++uyzDZo48VG9//6/VbduPUnSunVrNWfO/GIf6rZt26K33vqn0tPTde+9I/XDD7s1derzqlu3nh544B5t2LBOt9wSJcMo/D2kz1RhYYFmzHhOL788W3//+9wrevwux9FtZ5T2dU6FbiO4Sy017Fz7su+Xl5enjRs/UcuWrUpc3qdPf23YsM4emL755mvVrVvPoRpKSflRN9/cWx99tFFffPGpnn56olat+lB16tTV9OnTVL++n957b7Xy8nL15JOPKjAwSIMH364nnpisxMTVWrjwLfu6vL299cwzz+nqq5vpt9/26rHHHlLz5i100003l7DdH/TCC9P0wguz1L59J2VmHtfZs2clSXFxT6tp02ZavfpjHTiwT4899pBCQhrZg9xXX23S9OmzNWXKNC1evFAvvTRbb7zxtg4c2Kd//WuV3nxzuRo0CFBa2hEVFhaqUaPQEo89leWH/2zR7l82V+g22rSIUKtrb7ys+1TF15UkZWVl6tSpU/rgg0QZRqHy8vLKPL588kmy5syZr6CgIE2YMF4rVvxTDz44Tqmpv2nu3Jl68cV5uv76Vnr99Vd07FiG/X6lHaPP98VqtWr16o+1dm2iZs9+QR06dNaSJf/U0aNHdd99d6p37372AQ+Yh6kpKHcNGwZr4MDbZLFYdMstUcrMPK6srEwdPXpUP/+covvue1BeXl5q2/Yv9gOto1q0CFfPnn3k4eGhO+4YIav1nH78cY9++ilF2dkndM89sfL09FSjRqEaOHCwNm5cf8l13XhjhBo1CpWbm5vatWuvTp266Pvvd13p7lcJ69d/rHvuuU/16/upfv36uueeWK1bVxSmP/30Ew0YEK1mzcLk7e2te+4Zc8Xb69Gjp66/vpU8PDzUr1+k/vvf/0iStmzZrMaNGysy8lZ5eHiob99IXXVVU3311Zf2+57vi4eHhzw8isYWRoy4S7Vq1VazZmG6+uowdezYWY0ahap27drq3PlG/ec/v0iS6tatp5tv7i1vb2/VrFlLd901Wrt2fXvF++Pqpkx5QpGRN6t//x7avn2bYmJGldiub99Ibd68SXl5eZKKQkVfBz8E1qtXX8OGxcjDw0O9e/dTkyZXacuWzcrKytTXX2/RI49MkI+Pj+rX99OwYTGl1vJf/tJBYWHXyN3dXddc01x9+vTXd9/tLLFtUtIa3XrrQHXs2EXu7u4KCAjUVVc1VXr6Ue3e/Z3Gjh2nGjVqqHnzFoqKGmx/3UtS69Zt1bVrhCwWi/r3H6Bff/2vJMnd3SKr1arU1N+Un5+v4OAQAk4JqvLrSio6y8i9994vLy8v1ajh7dDxZcCAaDVpcpVq1PBWr1597ce+zz/fqBtvjFDbtn+Rl5eX7rvvwWKnMS7tGC1JFouHRo0aLQ8PD/Xp00/Z2dkaOvRvqlmzlpo1C1PTps20d++vDj2mqFiMiLugvn2v+tOj1ZXBz8/f/n9v76ILEeXm5io7O1u+vr7y8fGxL2/YMFgZGekOr/uPUwaK3kSDdPz4MUluysw8rsjIm+3LCwoKdcMNbS+5rq1bv9LSpYt18OAB++hFs2bXONyXPyO0b+QVj1ZXhuPHjysoKNh+u2HD4N8f56Jl57+Ol1Qu0zj++JqpUcNbubm5v2/rWLF+FPWlYbGRoZK2X3x9NS66nZWVKaloZG7+/Lnatm2rTp8+LUk6ezZHBQUFslgsV7xfjmjYufafGq2uSDNmzFHHjp1VUFCgzZu/0MMPj1FCwkr5+zco1i40tLGaNm2qr77apG7dbtLmzZu0dOk7Dm0jICCwWLAICip6jR09mvb7VIT/1UlhoVHq6+zHH3/QokULlJq6VzabTTabTT179i6xbUZGun2q3B8dP35cderUUc2atex/a9iwoX7+OcV+29+/+LHNaj2n/Px8hYY21vjxE7RkyRu/T3/qonHjHr9oGlZla3XtjZc9Wl2RqvLrSir6EFCjRg37bUeOL3/cd29vb+XmFn07c/z4MQUGNrQv8/HxUd26de23SztGS1LdunXt2/DyKuqTn5+ffXmNGjXs24K5COKoNA0aNNDp06eVm5trD+Pp6Ucv62JFfwzthYWFOnYsXQ0aBMhisSg4OETvvffvEu934TasVqueeeZJPfNMvLp3v1keHh6aPHkC50z9XYMGDZSenqZmzcIkFT1P50NFgwYNigXh0j5IXemFqBo0CFB6+qfF/paenq7Onf8XLq5kG++9l6ADB/brjTfelr9/A/33v7/onntG8Dr4ncViUY8evX6fN/2devbsc1Gb89MICgsL1bTp1QoNbezQuo8dy5BhGPbnLz39qCIiblJgYEN5enopKWmD/RuOPyrp+Y6Pf1q33z5Mc+bMV40aNTRv3lydPJld4nYDA4N0+PChi/7eoEEDnTp1SmfP5tjDeHp6ugICAh3an379ItWvX6Rycs5o9uwZWrhwvp599nkuxlaCqvi6KmkdV3J88fdvoP37U+238/LydPLk/y45X9oxGq6FqSmoNA0bBqtFi3C99dbrstls+v7774pNMXDEL7/8pC+++FT5+flaufJdeXp6qWXL1goPb6maNWspIeFtnTuXp4KCAv3226/66acfJRWNBJyftylJ+flFoxv16tWXxWLR1q1f6Ztvvi73fXYF+fn5OnfunP1ffn6++vTpr2XLlujEiRPKzs7W0qWL1a/fLZKknj37aO3aD7VvX6ry8vK0dOniS67bz89fJ0+e1JkzZ/5U37p27aaDBw9o/fpk5efna+PG9dq37zfdeOPlTWm6lLNnc1Sjhrdq1/bVqVMntWTJpfelOjr/I8PTp0/rqquuLrFN79799c03X2v16v9zePqAJGVnn9CqVe8pPz9fn366Qfv371PXrt3UoEEDderUWa+88g/l5JxRYWGhDh8+pF27iqYE1K/vp2PHMopd8e/s2bOqU6euatSooZSUH/TJJ8mX3G5U1CCtXZuoHTu++f3DfIb279+noKCGatWqjRYtekXnzp3Tr7/+V0lJa9SvX9n7dODAPu3cuV1Wq1VeXjVUo0YNubsXjUZeeOxB1XxdleRKji8339xbW7Zs1vfffyebzaY331xULMCXdoyGa2FEHJVq2rQXNH16nAYM6KWWLVsrMnJAsZDWt293zZkzXzfc0K7E+3fv3kMbN36iF16IU2hoqKZPf9E+ujF79stasOBlDR06SFarVU2aXGX/4UrPnn20bt3HGjCgt0JCQrRkyTt65JEnNHXqZNlsVnXr1l0RETdV/APghCZOfKTY7VGjRuuuu+7V2bM5uvvuOyQVPX533VV0jt2uXbtpyJA7NH78A3Jzc9Pdd9+ndevWytPT86J1X3VVU/Xp00/Dhg1SYWGBEhJWXdaoTd269TRr1j80b94czZ37dzVq1FizZv3DflaBKzVsWIzi4p5WVFQf+fsH6I47RujLLz8vl3W7sqeeelwWi7skNzVs2FBPPx1nH3m7UIMGDdSqVRt99923eu65v9v/PnLkMI0adc8lw8H117fUoUMHdOutvVW/vr9eeGGW/Qe4zzzznBYtWqCRI4fp7NkchYQ00ogRd0mS2rfvqKuvbqaBA/vL3d1NH320URMmPKVXXvmHXnppttq1+4t69epzyQ9/11/fSpMnT9OCBS/pyJEj8vPz0+OPP6WrrmqquLjpmjPn7xo8+Bb5+vrq3nvHqGPHLmU+XlarTYsWLdC+ffvk4eGh1q3b6Mknn5ZU8rHnxRdnSCo6d3Z1UpVfVyW5kuNLs2ZhevzxpxQf/7Ty8vI0fHhMsW9nSjtGw7W4GXwH6/R27typJk2uNbsbQIn27UvVqFHD9emnW0r8yhcA4FoOHPiPPvvsC40f/7D9tLWoGExNAXDZvvjiM9lsNp06dUoLF85Xt27dCeEAAFwmgjiAy7Zmzb8UFdVHw4cPlru7RRMmTDa7SwAAuByGsABctpdeWmB2FwAAcHmMiLsIpvIDAICKZhgGmaMSEcRdgKenl6zWPLO7AQAAqjirNY/TbVYigrgLaNQoRMeOHdG5c7l8SgUAAOXOMAydO5er9PSDOnIkrdiFkVBxmCPuAvz9/ZWXl6eDB1Pl4WGhMAAAQLkyDEOFhYVKSzuqAwcOKiAgoMTrQ6B8EcRdRKNGjWS1WrVmzYcqLDQkMTIOAADKm5tq166lwYMHmd2RaoEL+riYM2fO6OTJU8zfAgAA5c7T00P169dXjRo1zO5KtUAQBwAAAEzAjzUBAAAAExDEAQAAABMQxAEAAAAT/D9exaWXqaQkRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,5))\n",
    "\n",
    "colors = ['darkblue', 'darkred', 'darkorchid', 'darkolivegreen']\n",
    "labels = ['Ind. beta', 'Logit normal', 'Biv. beta const.', 'Biv. beta random']\n",
    "for i, name in enumerate(df1_grouped.index): \n",
    "    for j, df in enumerate([df1_grouped, df2_grouped, df3_grouped]): \n",
    "        if j == 0: label = labels[i]\n",
    "        else: label = ''\n",
    "        ax.plot([0.15*i+j,0.15*i+j], [df.loc[name, 'hdi_sens_lb'], df.loc[name, 'hdi_sens_ub']], \n",
    "                color = colors[i], alpha = 0.8, label=label)\n",
    "        ax.scatter([0.15*i+j,0.15*i+j],[df.loc[name, 'hdi_sens_lb'], df.loc[name, 'hdi_sens_ub']], \n",
    "                   color = colors[i], alpha = 0.8, marker = '_')\n",
    "        ax.scatter([0.15*i+j], [(df.loc[name, 'hdi_sens_lb']+df.loc[name, 'hdi_sens_ub'])/2], \n",
    "                   color = 'black', s = 100)\n",
    "        \n",
    "ax.legend(fontsize = 12, loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_xticks([0.25, 1.25, 2.25])\n",
    "ax.set_xticklabels(labels=['Vague priors', 'Strong priors with mean', 'Strong priors with mean and corr.'], \n",
    "                   fontsize = 12)\n",
    "\n",
    "#plt.savefig(\"../images/comparing_hdi_prior_approaches_sens-spec.pdf\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a07dc-80a3-4434-89a7-0fea4383c1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-emap",
   "language": "python",
   "name": "tcc-emap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
