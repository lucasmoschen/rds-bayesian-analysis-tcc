{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e650973-4fd0-4005-8433-bb6809e6b319",
   "metadata": {},
   "source": [
    "# Different prior approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1450ad28-59d1-44cd-9ad2-7a5f453eef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan as ps\n",
    "import stan_utility\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from utilits import ParameterAlpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af926931-9e9b-4dae-a94a-083e00b247c0",
   "metadata": {},
   "source": [
    "## The stan models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa02e70-beb6-4fac-a35a-a8eab01a215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_6f87d4736359dff09d821daa83abc844 NOW.\n"
     ]
    }
   ],
   "source": [
    "compiled = True        \n",
    "model = '../models/sensitivity_specificity/spec_sens_model_logit_normal'\n",
    "if compiled: sm_ln = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_ln = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_ln, f)\n",
    "\n",
    "compiled = True\n",
    "model = '../models/sensitivity_specificity/spec_sens_model_constant_alpha_smooth'\n",
    "if compiled: sm_cbb = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_cbb = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_cbb, f)\n",
    "        \n",
    "compiled = True\n",
    "model = '../models/sensitivity_specificity/spec_sens_model_random_alpha_smooth'\n",
    "if compiled: sm_rbb = pickle.load(open(model + '.pkl', 'rb'))\n",
    "else: \n",
    "    sm_rbb = ps.StanModel(file=model + '.stan')\n",
    "    with open(model+'.pkl', 'wb') as f:\n",
    "        pickle.dump(sm_rbb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8485c-8c3a-462f-a383-63d0b86d09f6",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a11259e-0069-47f1-8c2f-fd06384f1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(ro): \n",
    "    \n",
    "    sens = ro.beta(100, 0.15/0.85 * 100) \n",
    "    spec = ro.beta(100, 0.2/0.8 * 100)\n",
    "    n_neg = ro.poisson(50)\n",
    "    n_pos = ro.poisson(50)\n",
    "    y_pos = ro.binomial(n_pos, sens)\n",
    "    y_neg = ro.binomial(n_neg, spec)\n",
    "    \n",
    "    return sens, spec, n_neg, n_pos, y_pos, y_neg\n",
    "\n",
    "def evaluation(sens_post, spec_post, sens, spec): \n",
    "    \n",
    "    hits = np.zeros(2)\n",
    "    errors = np.zeros(2)\n",
    "    \n",
    "    hdi_sens = az.hdi(sens_post, hdi_prob=.75)\n",
    "    hdi_spec = az.hdi(spec_post, hdi_prob=.75)\n",
    "    if (sens > hdi_sens[0]) & (sens < hdi_sens[1]): \n",
    "        hits[0] += 1\n",
    "    if (spec > hdi_spec[0]) & (spec < hdi_spec[1]): \n",
    "        hits[1] += 1\n",
    "    errors[0] = (sens_post.mean() - sens)**2\n",
    "    errors[1] = (spec_post.mean() - spec)**2\n",
    "    \n",
    "    return hdi_sens, hdi_spec, hits, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0143b18-8745-40b7-8b7d-fa004ca85410",
   "metadata": {},
   "source": [
    "## Wrapper to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed900b7-2f0f-4928-97d9-e8e6dad0e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent_beta_model(n_neg, n_pos, y_pos, y_neg, parameters):\n",
    "    \n",
    "    a_s = parameters['a_s']\n",
    "    b_s = parameters['b_s']\n",
    "    a_e = parameters['a_e']\n",
    "    b_e = parameters['b_e']\n",
    "    sens_post = np.random.beta(a_s + y_pos, b_s + n_pos - y_pos, size=2000)\n",
    "    spec_post = np.random.beta(a_e + y_neg, b_e + n_neg - y_neg, size=2000)\n",
    "    \n",
    "    return evaluation(sens_post, spec_post, sens, spec)\n",
    "\n",
    "def logit_normal_model(n_neg, n_pos, y_pos, y_neg, parameters, stan_model):   \n",
    "\n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'mu_gamma': parameters['mu'], 'Sigma_gamma': parameters['Sigma']}\n",
    "    fit = stan_model.sampling(data=data, iter=4000, control={'max_treedepth': 12})\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "    return evaluation(sens_post, spec_post, sens, spec)\n",
    "\n",
    "def bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, parameters, stan_model): \n",
    "    \n",
    "    m1 = parameters['m1']\n",
    "    m2 = parameters['m2']\n",
    "    v1 = parameters['v1']\n",
    "    v2 = parameters['v2']\n",
    "    rho = parameters['rho']\n",
    "    alpha_hat = np.array(ParameterAlpha().mix_solver(m1, m2, v1, v2, rho))\n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'alpha_data':alpha_hat}\n",
    "    fit = stan_model.sampling(data=data, iter=4000)\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "\n",
    "    return evaluation(sens_post, spec_post, sens, spec), alpha_hat\n",
    "\n",
    "def bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, parameters, alpha_hat, stan_model): \n",
    "    \n",
    "    b = alpha_hat / parameters['var_alpha']\n",
    "    a = alpha_hat * b \n",
    "    data = {'n_pos':n_pos, 'n_neg':n_neg, 'Y_p':y_pos, 'Y_n':y_neg, \n",
    "            'a':a, 'b':b}\n",
    "    fit = stan_model.sampling(data=data, iter=4000, control = {'adapt_delta': 0.9})\n",
    "    sens_post = fit.extract()['sens']\n",
    "    spec_post = fit.extract()['spec']\n",
    "\n",
    "    return evaluation(sens_post, spec_post, sens, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e3db2-2c1d-4356-a5e6-d2fa8b7aa537",
   "metadata": {},
   "source": [
    "## Vague information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bac329-25eb-49e4-a7c7-13e7589682b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    independent_beta={'a_s': 1, 'b_s': 1, 'a_e': 1, 'b_e': 1}\n",
    "    logit_normal={'mu': [0,0], 'Sigma': 4*np.eye(2)}\n",
    "    bivariate_beta={'m1': 0.5, 'm2': 0.5, 'v1': 0.08, 'v2': 0.08, 'rho': 0, \n",
    "                    'var_alpha': np.array([1,1,1,1])}\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-vague-information.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a7073-4f68-47e0-bec7-8d254a93a188",
   "metadata": {},
   "source": [
    "## Information about means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b562ec-a424-4f6c-a8ac-33c8af9813c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276a5bf6a44042e2ac9236b57ea5c451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:3 of 8000 iterations saturated the maximum tree depth of 12 (0.0375 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations ended with a divergence (0.0125 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:130 of 8000 iterations ended with a divergence (1.62 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:3 of 8000 iterations saturated the maximum tree depth of 12 (0.0375 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:141 of 8000 iterations ended with a divergence (1.76 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:131 of 8000 iterations ended with a divergence (1.64 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:1 of 8000 iterations saturated the maximum tree depth of 12 (0.0125 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:2 of 8000 iterations saturated the maximum tree depth of 12 (0.025 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n",
      "WARNING:pystan:2 of 8000 iterations saturated the maximum tree depth of 12 (0.025 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 12 to avoid saturation\n"
     ]
    }
   ],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "independent_beta={'a_s': 5, 'b_s': 0.15/0.85 * 5, 'a_e': 5, 'b_e': 0.2/0.8 *5}\n",
    "logit_normal={'mu': [2.8, 2.25], 'Sigma': 4*np.eye(2)}\n",
    "bivariate_beta={'m1': 0.85, 'm2': 0.8, 'v1': 0.02, 'v2': 0.02, 'rho': 0, \n",
    "                'var_alpha': np.array([1,1,1,1])}\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-mean-information.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb406c-7158-4d93-b4ee-6fbd40998e6e",
   "metadata": {},
   "source": [
    "## Information about means and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2c49bc-48b8-486a-9346-b73cbe82f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c079770de846c099d86195fafd54e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Chain 4: E-BFMI = 0.19\n",
      "WARNING:pystan:E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
      "WARNING:pystan:85 of 8000 iterations ended with a divergence (1.06 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:116 of 8000 iterations ended with a divergence (1.45 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:69 of 8000 iterations ended with a divergence (0.863 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    }
   ],
   "source": [
    "ro = np.random.RandomState(10642189)\n",
    "columns =  ['simulation', 'n_neg', 'n_pos', 'y_pos', 'y_neg', 'sens', 'spec', 'hdi_sens', 'hdi_spec', 'hits', 'errors']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "independent_beta={'a_s': 5, 'b_s': 0.15/0.85 * 5, 'a_e': 5, 'b_e': 0.2/0.8 *5}\n",
    "logit_normal={'mu': [2.8, 2.25], 'Sigma': np.array([[4, -0.8], [-0.8, 4]])}\n",
    "bivariate_beta={'m1': 0.85, 'm2': 0.8, 'v1': 0.02, 'v2': 0.02, 'rho': -0.2, \n",
    "                'var_alpha': np.array([1,1,1,1])}\n",
    "\n",
    "for i in tqdm(range(1000)): \n",
    "    \n",
    "    sens, spec, n_neg, n_pos, y_pos, y_neg = experiment(ro)\n",
    "    \n",
    "    hdi_sens, hdi_spec, hits, errors = independent_beta_model(n_neg, n_pos, y_pos, y_neg, independent_beta)\n",
    "    df = df.append(dict(zip(columns, ['ind_beta', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = logit_normal_model(n_neg, n_pos, y_pos, y_neg, logit_normal, sm_ln)\n",
    "    df = df.append(dict(zip(columns, ['logit_normal', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    (hdi_sens, hdi_spec, hits, errors), alpha_hat = bivariate_beta_constant_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, sm_cbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_constant', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    hdi_sens, hdi_spec, hits, errors = bivariate_beta_random_model(n_neg, n_pos, y_pos, y_neg, bivariate_beta, alpha_hat, sm_rbb)\n",
    "    df = df.append(dict(zip(columns, ['bivariate_random', n_neg, n_pos, y_pos, y_neg, sens, spec, hdi_sens, hdi_spec, hits, errors])), \n",
    "              ignore_index=True)\n",
    "    \n",
    "    df.to_csv('../data/experiments/prior-sens-spec-experiments-mean-corr-information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086aaab4-66a7-4e4c-aa5c-4b35d75b6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-vague-information.csv', index_col=0)\n",
    "df2 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-mean-information.csv', index_col=0)\n",
    "df3 = pd.read_csv('../data/experiments/prior-sens-spec-experiments-mean-corr-information.csv', index_col=0)\n",
    "\n",
    "df1['hits_sens'] = df1.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hits_spec'] = df1.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['errors_sens'] = df1.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['errors_spec'] = df1.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['hdi_sens_lb'] = df1.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hdi_sens_ub'] = df1.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1['hdi_spec_lb'] = df1.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df1['hdi_spec_ub'] = df1.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df1 = df1.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])\n",
    "\n",
    "df2['hits_sens'] = df2.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hits_spec'] = df2.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['errors_sens'] = df2.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['errors_spec'] = df2.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['hdi_sens_lb'] = df2.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hdi_sens_ub'] = df2.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2['hdi_spec_lb'] = df2.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df2['hdi_spec_ub'] = df2.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df2 = df2.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])\n",
    "\n",
    "df3['hits_sens'] = df3.hits.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hits_spec'] = df3.hits.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['errors_sens'] = df3.errors.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['errors_spec'] = df3.errors.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['hdi_sens_lb'] = df3.hdi_sens.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hdi_sens_ub'] = df3.hdi_sens.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3['hdi_spec_lb'] = df3.hdi_spec.apply(lambda x: float(x.strip('[]').split()[0]))\n",
    "df3['hdi_spec_ub'] = df3.hdi_spec.apply(lambda x: float(x.strip('[]').split()[1]))\n",
    "df3 = df3.drop(columns = ['hits', 'errors', 'hdi_sens', 'hdi_spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98dd39d8-6a77-4482-a8cd-9569d0ffdea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.788265</td>\n",
       "      <td>0.898020</td>\n",
       "      <td>0.739975</td>\n",
       "      <td>0.862021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.792734</td>\n",
       "      <td>0.899696</td>\n",
       "      <td>0.748013</td>\n",
       "      <td>0.866589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.789246</td>\n",
       "      <td>0.900130</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.859847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.794526</td>\n",
       "      <td>0.904236</td>\n",
       "      <td>0.739859</td>\n",
       "      <td>0.864193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.756      0.755     0.002388     0.002625   \n",
       "bivariate_random        0.749      0.744     0.002264     0.002546   \n",
       "ind_beta                0.738      0.761     0.002531     0.002843   \n",
       "logit_normal            0.741      0.745     0.002405     0.002811   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.788265     0.898020     0.739975     0.862021  \n",
       "bivariate_random       0.792734     0.899696     0.748013     0.866589  \n",
       "ind_beta               0.789246     0.900130     0.735210     0.859847  \n",
       "logit_normal           0.794526     0.904236     0.739859     0.864193  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_grouped = df1.groupby('simulation').mean()\n",
    "df1_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f95c77-3616-432d-96f0-930b247778ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.805747</td>\n",
       "      <td>0.908645</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.866820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.797803</td>\n",
       "      <td>0.904222</td>\n",
       "      <td>0.744944</td>\n",
       "      <td>0.864393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.806542</td>\n",
       "      <td>0.909443</td>\n",
       "      <td>0.749720</td>\n",
       "      <td>0.867123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.810880</td>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.752838</td>\n",
       "      <td>0.873922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.752      0.750     0.001952     0.002316   \n",
       "bivariate_random        0.747      0.748     0.002167     0.002454   \n",
       "ind_beta                0.741      0.736     0.002009     0.002363   \n",
       "logit_normal            0.699      0.712     0.002300     0.002797   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.805747     0.908645     0.749375     0.866820  \n",
       "bivariate_random       0.797803     0.904222     0.744944     0.864393  \n",
       "ind_beta               0.806542     0.909443     0.749720     0.867123  \n",
       "logit_normal           0.810880     0.915287     0.752838     0.873922  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_grouped = df2.groupby('simulation').mean()\n",
    "df2_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a334f498-7153-478b-ad59-b82cc5c6a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neg</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>y_neg</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>hits_sens</th>\n",
       "      <th>hits_spec</th>\n",
       "      <th>errors_sens</th>\n",
       "      <th>errors_spec</th>\n",
       "      <th>hdi_sens_lb</th>\n",
       "      <th>hdi_sens_ub</th>\n",
       "      <th>hdi_spec_lb</th>\n",
       "      <th>hdi_spec_ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bivariate_constant</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.805547</td>\n",
       "      <td>0.909015</td>\n",
       "      <td>0.748608</td>\n",
       "      <td>0.866570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_random</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.795936</td>\n",
       "      <td>0.903484</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.862734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_beta</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.806450</td>\n",
       "      <td>0.909415</td>\n",
       "      <td>0.749895</td>\n",
       "      <td>0.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_normal</th>\n",
       "      <td>50.181</td>\n",
       "      <td>50.442</td>\n",
       "      <td>42.918</td>\n",
       "      <td>40.293</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.812067</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.753844</td>\n",
       "      <td>0.874486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_neg   n_pos   y_pos   y_neg      sens      spec  \\\n",
       "simulation                                                               \n",
       "bivariate_constant  50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "bivariate_random    50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "ind_beta            50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "logit_normal        50.181  50.442  42.918  40.293  0.851309  0.800682   \n",
       "\n",
       "                    hits_sens  hits_spec  errors_sens  errors_spec  \\\n",
       "simulation                                                           \n",
       "bivariate_constant      0.743      0.749     0.001989     0.002364   \n",
       "bivariate_random        0.745      0.755     0.002229     0.002504   \n",
       "ind_beta                0.743      0.742     0.002007     0.002365   \n",
       "logit_normal            0.684      0.715     0.002303     0.002804   \n",
       "\n",
       "                    hdi_sens_lb  hdi_sens_ub  hdi_spec_lb  hdi_spec_ub  \n",
       "simulation                                                              \n",
       "bivariate_constant     0.805547     0.909015     0.748608     0.866570  \n",
       "bivariate_random       0.795936     0.903484     0.742036     0.862734  \n",
       "ind_beta               0.806450     0.909415     0.749895     0.867188  \n",
       "logit_normal           0.812067     0.915993     0.753844     0.874486  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_grouped = df3.groupby('simulation').mean()\n",
    "df3_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758f4897-4b51-456f-9389-7bcec3f482e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,5))\n",
    "\n",
    "colors = ['darkblue', 'darkred', 'darkorchid', 'darkolivegreen']\n",
    "labels = ['Ind. beta', 'Logit normal', 'Biv. beta const.', 'Biv. beta random']\n",
    "for i, name in enumerate(df1_grouped.index): \n",
    "    for j, df in enumerate([df1_grouped, df2_grouped, df3_grouped]): \n",
    "        if j == 0: label = labels[i]\n",
    "        else: label = ''\n",
    "        ax.plot([0.15*i+j,0.15*i+j], [df.loc[name, 'hdi_sens_lb'], df.loc[name, 'hdi_sens_ub']], \n",
    "                color = colors[i], alpha = 0.8, label=label)\n",
    "        ax.scatter([0.15*i+j,0.15*i+j],[df.loc[name, 'hdi_sens_lb'], df.loc[name, 'hdi_sens_ub']], \n",
    "                   color = colors[i], alpha = 0.8, marker = '_')\n",
    "        ax.scatter([0.15*i+j], [(df.loc[name, 'hdi_sens_lb']+df.loc[name, 'hdi_sens_ub'])/2], \n",
    "                   color = 'black', s = 100)\n",
    "        \n",
    "ax.legend(fontsize = 12, loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_ylabel(r'Sensitivity $\\gamma_s$', fontsize=16)\n",
    "\n",
    "ax.set_xticks([0.25, 1.25, 2.25])\n",
    "ax.set_xticklabels(labels=['Vague priors', 'Strong priors with mean', 'Strong priors with mean and corr.'], \n",
    "                   fontsize = 12)\n",
    "\n",
    "plt.savefig(\"../images/comparing_hdi_prior_approaches_sens-spec.pdf\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a07dc-80a3-4434-89a7-0fea4383c1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-emap",
   "language": "python",
   "name": "tcc-emap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
