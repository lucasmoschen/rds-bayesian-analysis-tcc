This work proposes to study the survey method Respondent-Driven Sampling (RDS), a chain-referral method with the objective of sampling from hard-to-reach populations when necessary to estimate the prevalence of some binary condition from this population. The modeling also accounts for sensibility and sensitivity since the imperfection of the detection tests.  

Hidden or hard-to-reach populations have two main features: no sampling frame
exists, given that their size and boundaries are unknown, and there are
privacy concerns because the subjects are stigmatized or have illegal behavior
\cite{heckathorn1997}. Fear of exposition or prosecution complicates the
enumeration of the populations and the learning about them. Moreover, if the
occurrence frequency of the condition is low, there are high logistic costs
involved. Some examples are heavy drug users, sex workers, homeless people,
and men who have sex with men. 

Researches have been done with the development of some methods to reach these
populations, such as, for example, snowball sampling \cite{goodman1961}, key
important sampling \cite{deaux-callaghan1985}, 
and targeted sampling \cite{watters-biernacki1989}. \citeauthor{heckathorn1997} introduced the Respondent-Driven Sampling (RDS) to
fill some gaps from other methods he depicted in his work. In his proposed
approach, the researchers select a handful of individuals from the target
population and give them coupons to recruit their peers. The individuals
receive a reward for being recruited and for recruiting, which creates a dual
incentive system. After \citeyear{heckathorn1997}, several papers studied this
topic more deeply. 

Following the sampling from the target population, a questionnaire or a
disease test is conducted. This work considers binary outcomes. For
instance, asking about smoking status or testing for HIV infections. However,
the diagnoses are subject to measure error, and regard their accuracy is a
vital step \cite{reitsma2005bivariate}. In particular, we propose the joint
use of sensitivity (the ability to detect the condition) and specificity (the
ability to identify the absence of it).  

Nevertheless, because of our lack of knowledge about nature itself, it is
necessary to model the uncertainty of this process, and Bayesian Statistics is
the indicated area of study. In the Bayesian view, the parameters are random
variables, and the beliefs about them are updated given new data. The idea is
to propagate uncertainty about the outcome through the network of contacts,
which has its probability distribution.

The objective of this work is to analyze the network structure as a stochastic object, along with the sensibility and sensitivity. We also intend to apply this framework efficiently, comparing Monte Carlo algorithms and Laplace approximations.

\section{Respondent-driven sampling}

RDS is commonly used to survey hidden or hard-to-reach populations when
no sampling frame exists \cite{heckathorn1997}. In this approach, the
researchers select some individuals, called {\em seeds} from the target
population, and give them a fixed amount of {\em recruitment coupons} to
recruit their peers. Each recipient of the coupons reclaims it in the study
site, is interviewed, and receives more coupons to continue the recruitment.
This process occurs until it reaches some criteria. The sampling is without
replacement, so the participants cannot be recruited more than once. Moreover,
the respondents inform their {\em network degree}.

The subjects receive a reward for being interviewed and for each recruitment
which establishes a dual system incentive. The {\em primary incentive} is the
{\em individual-sanction-based control}, so there is a reward for
participating. The second one is the {\em group-mediated social control} that
influences the participants seeking to induce others to comply. When social
approval is important, recruitment can be even more efficient and cheaper.
Moreover, the material incentive can be converted into symbolic by the
individuals. 

In a survey, questions about ethnicity, location (not necessarily fixed),
gender, and religion, create possible (finite) states in which each
participant is. By statistical tests, one can verify the association between
the recruiter and recruited responses. \citeauthor{heckathorn1997} models it
as a Markov chain where the states are the possible answers, and the links are
the recruitments. Considering an ergodic chain, an equilibrium mix of recruits
will be attained when the number of waves goes to infinity, and it approaches
the equilibrium at a geometric rate. Therefore, we obtain the distribution of
the states posterior to enough waves. Posterior studies \cite{heckathorn2002}
explained how to access bias and other statistical considerations. 

Besides considering only the states where the individual is located,
\cite{crawford2016} analyses the network structure given by RDS with a
continuous-time model incorporating the recruitment time, the network degree,
and the pattern of coupon use. This configuration enables the treatment of
unobserved links and nodes as missing data. Let $G = (V,E)$ be an undirected
graph representing the hidden population. The {\em recruitment graph} $G_R =
(V_R, E_R)$ represents the recruited individuals and the recruitment edge.
Given that each individual can be sampled only once, it is not possible to
observe the {\em recruitment-induced subgraph}, that is the induced subgraph
generated by $V_R$. Moreover, the {\em coupon matrix} $C$ defined by $C_{ij} =
1$ if the i$^{th}$ subject has at least one coupon before the j$^{th}$
recruitment event, is also observed with the recruitment times. Assuming an
exponential and independent distribution of the times, the likelihood can be
written, and the distribution interpreted as an exponential random graph
model. 

These models allowed several applications in social sciences, epidemiology,
and statistics, including hidden populations size estimation
\cite{crawford2018hidden}, regression \cite{bastos2012binary}, communicable
disease prevalence estimation \cite{albuquerque2009avaliaccao}, among others. 

\section{Prevalence estimation with imperfect tests}

Consider a population of interest and a known condition, such as, for example,
a disease or a binary behavior. It is important to understand the proportion
of individuals in this population exposed at time $t$, called {\em
prevalence}. In hidden networks, the population size is unknown prior to the
study, what makes the proceeding to be hard. Suppose a diagnostic test is done to measure the presence or the
absence of this condition in the individuals. 

Mathematically, let $\theta \in (0,1)$ be the prevalence of a condition and
$Y_i$ be an  indicator function of the condition in the i$^{th}$ individual.
Assuming for simplicity that all tests are performed at time $t$, and the
sample is $\{y_1, ..., y_n\}$, the RDS estimator was
proposed based largely on Markov chain theory and social network theory
\cite{heckathorn1997, heckathorn2002}. 

\begin{equation}
    \label{eq:rdsI}
     a = 1
\end{equation}

\lucas{Citar} \cite{volz2008probability} para o estimador RDS II. 

\section{Bayesian statistics}

There are two more common interpretations of probability and statistics:
frequentist inference and Bayesian inference. While the frequentists defines
probability as the limit of a frequency in a large number of trials, the
Bayesians represents an individual's degree os belief in a statement which are
updated given new information. This philosophy allows to assign probabilities
to any statement, even if a random process is not defined. 



Bayes’ theorem shows the relation between two conditional probabilities that are the reverse
of each other. This theorem is named after Reverend Thomas Bayes (1701-1761), and is also
referred to as Bayes’ law or Bayes’ rule (Bayes and Price 1763) 2 . Bayes’ theorem expresses
the conditional probability, or ‘posterior probability’, of an event A after B is observed in
terms of the ‘prior probability’ of A, prior probability of B, and the conditional probability
of B given A. Bayes’ theorem is valid in all common interpretations of probability. The two
(related) examples below should be sufficient to introduce Bayes’ theorem.

% The components 6 of Bayesian inference are
% 1. p(Θ) is the set of prior distributions for parameter set Θ, and uses probability as a
% means of quantifying uncertainty about Θ before taking the data into account.
% 2. p(y|Θ) is the likelihood or likelihood function, in which all variables are related in a full
% probability model.
% 3. p(Θ|y) is the joint posterior distribution that expresses uncertainty about parameter
% set Θ after taking both the prior and the data into account. If parameter set Θ is
% partitioned into a single parameter of interest φ and the remaining parameters are
% considered nuisance parameters, then p(φ|y) is the marginal posterior distribution.