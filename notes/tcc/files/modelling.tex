\chapter{Prevalence modelling and regression methods}

\textcite[p. 311]{fisher1922mathematical} stated that the objective of
statistics is to reduce the data since its volume is impossible 
to comprehend by the researchers. In that sense, few parameters should represent the whole phenomenon catching the most relevant information. 
Years later, Newman studied the theory of modelling which can be divided 
in three aspects \cite[p. 161]{lehmann2012model}: 

\begin{alineas}
  \item models of complex phenomena are created by putting together 
  simple building elements that the researcher is familiar with and can 
  handle; 
  \item there are two types of models: the \textit{explanatory models}, 
  which will be focused on this work, and the \textit{interpolatory formulae}. 
  \item An explanatory theory necessitates a thorough understanding of the scientific context of the problem. In this regard, we investigated questions involving Respondent-driven sampling and prevalence estimation as introduced in Chapter \ref{ch:theoretical-background}. 
\end{alineas}

In this chapter, we develop models that enclose these ideas building each 
block separately. For a Bayesian modelling, we assume that each parameter
of the model has a probability distribution that incorporates the 
researcher's uncertainty about it. For each individual, we observe $k$ 
covariates that are possible risk factors represented by the vector 
$\x_i \in \R^{k}$ of the $i^{th}$ individual. We denote $\theta_i$ the 
probability of the $i$-th individual have been exposed to the disease
that depends on the prevalence $\theta$ and $\x_i$. We also consider the
dependence of sampling from RDS as a spatial random effect. The probability of
positive test in the $i^{th}$ individual is denoted by $p_i$.  

Another important feature of the model is that sensitivity and 
specificity have the same distribution for all individuals and 
it only depends on the test used to diagnose. This is an assumption 
that must be analysed for each particular case. For instance, COVID-19 
Sofia test has different sensitivity and specificity for symptomatic and 
asymptomatic individuals \cite[Table 1][p. 3]{mitchell2021performance}.  

From above, we develop three different models: the first considers perfect 
tests, that is, $\gamma_s = \gamma_e = 1$ and no spatial random effect; 
the second considers imperfect tests, regarding $\gamma_s$ and $\gamma_e$, 
but ignoring the RDS structure; and the third one has imperfect tests and 
RDS structure. \improve{Some considerations are made to improve the model's
limitations.}

The implementation of the following models were in the statistical computation
platform Stan \cite{carpenter2017stan} within Python Interface PyStan
\cite{pystan} which uses an implementation for HMC algorithm. All the codes
are written in \autoref{appendix:stan-codes}.

\section{Perfect tests}

The first model supposes the samples are independent and the test is perfect,
which means that $\theta_i = p_i$ for all $i$. Therefore it only considers the risk factors $\x_i$. 

\begin{equation}
  \label{model:perfect-tests}
  \begin{aligned}
    Y_i \mid \theta_i &\sim \bern(\theta_i), \\
    g(\theta_i) &= g(\theta) + \x_i^T\beta, 
  \end{aligned}  
\end{equation}
where $g(\cdot)$ is the $\logit$ function.
The parameter $\beta \in \R^{k}$ is the risk effects. For Bayesian inference, priors on
$\beta$ and $\theta$ must be included. We use $\beta ~ \sim \N(\mu_{\beta}, \Sigma_{\beta})$
and $\theta \sim \betadist(a^{p}, b^p)$, where the vector $\mu_{\beta}
\in \R^{k}$, the symmetric positive-definite matrix $\Sigma_{\beta} \in
\R^{k\times k}$, and the positive real values $a^p, b^p \in \R_{>0}$ are fixed
hyperparameters. Inferences about $\beta$ and $\theta$ are based on the
posterior distribution. Keeping the notation of
Section \ref{sec:glm}, we denote $\boldsymbol{X}$ the covariate matrix. 

\begin{remark}[Interpretation of prevalence]
  \label{remark:interpretation-prevalence}
  According to the model formulation, if the risk factors are zero, i.e $\x_i
  = 0$, the probability of the $i$-th individual having been exposed is the prevalence $\theta$, which means that in
a population with no risk effects, the probability of a person having the
disease is exactly the proportion in this population. 
\end{remark}

\subsection{Identifiability}
\label{sec:perfect-test-identifiability}

A formal definition for identifiability regards the likelihood function \cite[p.
3459]{xie2006measures}:

\begin{definition}
  \label{def:identifiability}
  Let $\mathcal{P} = \{P_{\theta} : \theta \in \Theta\}$ be
  the family of probability distributions for $\mathcal{Y}$. This model is
  {\em identifiable} if for any $\theta', \theta'' \in
  \Theta$, 
  $$\forall y \in \mathcal{Y}, P_{\theta'}(Y = y) =
  P_{\theta''}(Y = y) \implies
  \theta' = \theta''.$$ 
\end{definition} 

The family distribution from model \eqref{model:perfect-tests} is the logistic
regression parametrized by $(\theta, \beta)$ and conditioned on
observing the regressor $\boldsymbol{X}$, with $\mathcal{Y} = \{0,1\}^n$. Defining $\beta_0 =
g(\theta)$, we may rewrite it as 
$$Y_i \mid \tilde{\beta}, \tilde{\x}_i \sim \bern(g^{-1}(\tilde{\x}_i^T\tilde{\beta})),$$
such that $\tilde{\beta}$ concatenate $\beta_0$ and $\beta$, and $\tilde{\x}_i$
concatenate $1$ and $\x_i$. \textcite[p. 7]{kuchenhoff1995identification}
gives a formal proof for the identifiability of this representation.

In the Bayesian paradigm, inferences are based on the posterior distribution.
Therefore, identifiability should consider the prior distribution.
\textcite[p. 46]{lindley1972bayesian}  argued that proper priors are
sufficient to handle
identifiability problems in the Bayesian perspective, which means that a
well-defined posterior probability distribution is enough for parameter
identification. A formal definition for {\em Bayesian identifiability} is the
following: if $p(\theta \mid \beta, y, \boldsymbol{X}) = p(\theta \mid
\beta)$, the data $y$ is uninformative for $\theta$ when $\beta$ is known. 
The definition is analogous if $\beta$ and $\theta$ change places. However,
\textcite[p. 248]{gelfand1999identifiability} proved that this definition is equivalent to
likelihood identifiability. 

Despite the identifiability of the model, it may be hard to sample from
the posterior distribution depending on the value of $\x$. As an example, 
consider the following experiment: 

\begin{enumerate}[label=(\roman*)]
  \item generate $500$ covariates $X_i \sim \N(15, 1)$;
  \item let $\beta = 0.1$, $\theta = 0.1$, and $\theta_i = g^{-1}(g(\theta) +
  X_i\beta)$ for $1 \le i \le 500$;
  \item for each $i$, sample $Y_i \sim \bern(\theta_i)$;
  \item let $a^p = 1$, $b^p = 1$, $\mu_{\beta} = 0$, and $\Sigma_{\beta} = 1$
  the hyperparameters for the prior distributions (weakly informative);
  \item make 1000 warm-up and 1000 sampling iterations using Stan given the
  data $(Y_1, X_1), \dots, (Y_n, X_n)$.  
  \item make 2000 warm-up and 2000 sampling iterations using Stan given the
  data $(Y_1, X_1), \dots, (Y_n, X_n)$.
\end{enumerate}

The HMC sampler took around 8.39s.
\autoref{fig:result-uncentered-mean} presents the results through the posterior
distribution, the trace plot, and the strong posterior
correlation between $\theta$ and $\beta$. To address this 
problem, subtracting the mean $\bar{x}$ is a default procedure \cite[p.
5]{ogle2020ensuring}. After centering the data around the mean, the HMC
sampler took around 1.39s, and the improved results are shown in
\autoref{fig:result-centred-mean}. 

\begin{figure}
  \centering  
  \caption{\label{fig:result-uncentered-mean}Posterior
  distribution, trace plot, and posterior samples of parameters 
  $\theta$ and $\beta$ from model \eqref{model:perfect-tests} with uncentered covariate.}
  \includegraphics[width=14cm]{identifiability_perfect_tests_unscaled_x.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

\begin{figure}
  \centering  
  \caption{\label{fig:result-centred-mean}Posterior
  distribution, trace plot, and posterior samples of parameters 
  $\theta$ and $\beta$ from model \eqref{model:perfect-tests} with centralized covariate.}
  \includegraphics[width=14cm]{identifiability_scaled_x.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

We observe that the interpretation of prevalence from Remark
\ref{remark:interpretation-prevalence} changes from centred and 
uncentered since the meaning of $\x_i = 0$ is different. Along with this
discussion, it is usual to divide the centred variable by its
standard deviation, to put all predictors on a common scale. Discussions about
the problems caused by standardizing are outside the scope of this work. 
\textcite{gelman2008scaling} suggests to divide de continuous variables by 2
times de standard deviation to allow ``the coefficients to be interpreted in
the same way as binary deviation.'' \cite[p. 2867]{gelman2008scaling} Binary
inputs are not standardized since their coefficients are easily interpretable.

Other identifiability problems arising from the input variables are
collinearity and {\em separation} \cite[p. 1360-1361]{gelman2008weakly}. 
The latter occurs if a linear combination of a subset of the predictors gives
a perfect prediction for the binary outcome. For instance, when a linear
combination of the predictors is greater than a threshold if and only if $y =
1$.  

\subsection{Simulated data}

To present a sanity check about the functionality of model
\eqref{model:perfect-tests} and to validate the properties of the estimation
procedure, we simulate fake data from the model and make inferences about the
result. We follow the experiment from Section
\ref{sec:perfect-test-identifiability}.
\autoref{table:experiments-perfect-test} summarizes the experiment
parameters. 

\begin{table}[!ht]
  \centering
  \caption{\label{table:experiments-perfect-test}Experiment settings for the
  simulation of model \eqref{model:perfect-tests}.}
  \begin{tabular}{ccccccc}
  \hline
  Exp & $n$ & $k_{c}$ (normal) & $k_{c}$ (cauchy) & $k_{b}$ & $\beta$ & $\theta$ \\ \hline
  \multicolumn{1}{c}{1} & 100 & 3 & 0 & 2 & {[}-0.1, 2.5, 1.4, -1.8, 0.3{]} & 0.05 \\
  \multicolumn{1}{c}{2} & 100 & 3 & 0 & 2 & {[}-0.1, 2.5, 1.4, -1.8, 0.3{]} & 0.9 \\
  \multicolumn{1}{c}{3} & 100 & 2 & 2 & 1 & {[}-0.1, 2.5, 1.4, -1.8, 0.3{]} & 0.1 \\
  \multicolumn{1}{c}{4} & 5000 & 40 & 5 & 5 & $F$ distribution & 0.1 \\\hline
  \end{tabular}
  \fonte{Prepared by the author (2021). We denote $n$ for number of samples,
  $k_c$ for the number of continuous variables, and $k_b$ for binary variables. Between
  paranthesis, \textit{normal} means that the variables were generated from a
  Multivariate Normal with prespecified parameters, and \textit{cauchy} from a
  Cauchy distribution. $F$ distribution is $\N(\mu = 0, \sigma = 2)$ with
  probability 0.3, and 0 otherwise.}
\end{table}

We primally look at the settings from experiment 1. With a non-informative prior for $\theta$
(Jeffreys prior $\betadist(1/2, 1/2)$) and a weakly informative for $\beta$
(zero mean and covariance matrix four times the identity matrix),
\autoref{fig:result-experiment1-perfect-test} shows the posterior
distributions for the parameters. The prevalence estimate is good despite
Jeffreys' prior. When the distance between the prior and the true value is large, the
inferences seem to be biased. However, this makes sense regarding the model. For
instance, for $\beta_2$, before observing the data, we put 0.7 mass probability
for values less than 0.1. The data decreased it to 0.125. This highlights
the importance of a well defined prior distribution. The values for Bulk ESS
was greater than 3000 for all parameters, while Tails ESS were greater that
2200 with 1000 warmup and 1000 sampling iterations, and 4 chains. For all
parameters $\hat{R} = 1$. Trace plots and scatter plots were also good and we
omit here since they do not bring new information for the discussion. 

\begin{figure}[!ht]
  \centering  
  \caption{\label{fig:result-experiment1-perfect-test}Posterior
  distribution for parameters of model \eqref{model:perfect-tests}.}
  \includegraphics[width=14cm]{posterior_perfect_tests_exp1.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

Although we are performing Bayesian inference, frequentist properties can me
accessed through simulation. After 1000 simulations varying the input data
$Y$, the 75\% credible interval included the true parameters in 75.8\%, 78.8\%,
76.4\%, 77.5\%, 67.3\%, and 72.2\% of the times, respectively for $\theta,
\beta_1, \dots, \beta_5$. Each simulation had 100 samples and weakly
informative priors for $\beta$ and $\theta$.
\autoref{fig:predicted-vs-simulated-perfect-tests} compares the predicted and
simulated probabilities. The green area is delimited by the curves generated
by $2\sqrt{\theta_i(1-\theta_i)/n}$, where $n=500$ is the number of points. 
It was increased to show a larger variety of points. This area is a $\pm 2$
standard-error bounds. 

\begin{figure}[!ht]
  \centering  
  \caption{\label{fig:predicted-vs-simulated-perfect-tests}Comparing predicted
 and simulated probabilities of having the disease from model \eqref{model:perfect-tests}.}
  \includegraphics[width=10cm]{predicted-vs-simulated-perfect-tests.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

Experiment 2 is used to see if these properties repeat when the prevalence is
higher. The same regressors were used for the comparison, but the input data
$Y$ were generated with different prevaleces. With prevalence being 0.9, the
estimates were a little high for all coefficients as
\autoref{fig:comparing-diff-prevalence-perfect-tests} presents. This is
related to the fact that the posterior mean underestimated the true value for this
experiment. After increasing the number of samples, the estimates were closer,
as expected. 

\begin{figure}[!ht]
  \centering  
  \caption{\label{fig:comparing-diff-prevalence-perfect-tests}Comparing
  posterior mean and 94\% credibility intervals for $\beta$ in model \eqref{model:perfect-tests} with the same regressors
  $\boldsymbol{X}$ but different prevalences.}
  \includegraphics[width=12cm]{comparing-diff-prevalence-perfect-tests.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

The third experiment aims to analyse what happens if some covariates have a
heavier tail. No big difference was noticed despite the existence of some
individuals very different from the others. At last, the fourth experiment
increases the dimensionality to observe the number of effective samples. Each
chain took around 3 minutes, instead of the 3s needed for the previous
experiments. From the 51 parameters, 48 had the true values in the 95\% HDI
credible interval. The Bulk ESS was greater than 4500 for 95\% of the
parameters. \autoref{fig:predicted-vs-simulated-high-dimension-perfect-tests}
presents how the predicted probabilities for each individual behaves in this
case. Here the green area is delimited by the 95\% credible interval. 

\begin{figure}[!hb]
  \centering  
  \caption{\label{fig:predicted-vs-simulated-high-dimension-perfect-tests}
  Comparing predicted and simulated probabilities of having the disease from
  model \eqref{model:perfect-tests} with high dimension.}
  \includegraphics[width=10cm]{predicted-vs-simulated-high-dimension-perfect-tests.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure} 

\section{Sensitivity and specificity}

In this section, we describe a model for estimating the sensitivity and
specificity of a diagnostic test. This model is relevant to analyze and
experiment with different prior specification approaches. Suppose having a
gold standard test and another test, for instance, a simpler, faster, or less
invasive one, which we want to estimate the accuracy by the sensitivity and
specificity. In this scenario,
true positive (negative) individuals are those who tested positive (negative) by
the gold standard. Therefore, in a population with $n_{\gamma_s}$ true
positives and  $n_{\gamma_e}$ true negatives, we denote 
\begin{equation}
  \label{model:sensitivity-specificity}
  \begin{aligned}
    y_{\mathrm{pos}} &\mid \gamma_s \sim \operatorname{Binomial}(n_{\gamma_s}, \gamma_s),\ \\
    y_{\mathrm{neg}} &\mid \gamma_e \sim \operatorname{Binomial}(n_{\gamma_e}, \gamma_e), 
  \end{aligned}
\end{equation}
such that $y_{\mathrm{neg}}$ are negative tests on known negative 
subjects and $y_{\mathrm{pos}}$ are positive tests on
known positive. In the Two-by-two formulation from \autoref{table:two-by-two},
we have

\begin{quadro}[!ht]
  \centering
  \caption{\label{table:two-by-two-data}Two-by-two table with the model specification.}
  \begin{tabular}{c|c|c|c|}
  \cline{2-4}
                                               & $Y = 0$ & $Y = 1$ & Total\\ \hline
  \multicolumn{1}{|c|}{$Y^{\mathrm{true}}= 0$} & $y_{\mathrm{neg}}$  & $n_{\gamma_e} - y_{\mathrm{neg}}$ & $n_{\gamma_e}$ \\ \hline
  \multicolumn{1}{|c|}{$Y^{\mathrm{true}}= 1$} & $n_{\gamma_s} -
  y_{\mathrm{pos}}$    & $y_{\mathrm{pos}}$  & $n_{\gamma_s}$  \\ \hline
  \multicolumn{1}{|c|}{Total} & $n_{\gamma_s} + y_{\mathrm{neg}} -
  y_{\mathrm{pos}}$ & $n_{\gamma_e} + y_{\mathrm{pos}} - y_{\mathrm{neg}}$ &
  $n_{\gamma_s} + n_{\gamma_e}$ \\\hline
  \end{tabular}
  \fonte{Prepared by author (2021).}
\end{quadro}

In Bayesian analysis, we have to define a prior distribution with density $\pi$ for the
parameters $(\gamma_e, \gamma_s)$. For this, we consider three different approaches: 

\begin{alineas}
  \item prior distributions are specified independently for each parameter and
  each one has a beta distribution, i.e,  
  $$\pi(\gamma_e, \gamma_s) =
  \pi(\gamma_e)\pi(\gamma_s) \propto \gamma_s^{a_s}(1-
  \gamma_s)^{b_s}\gamma_e^{a_e}(1-\gamma_s)^{b_e},$$
  for $a_s, b_s, a_e,$ and $b_e$ being pre-determined positive real hyperparameters;
  \item bivariate normal distribution in the log odds space, i.e,  
  $$(\logit(\gamma_e), \logit(\gamma_s)) \sim
  \N(\mu_{\gamma}, \Sigma_{\gamma}),$$
  such that the vector $\mu_{\gamma} \in \R^2$ and the covariance matrix
  $\Sigma_{\gamma} \in \R^{2\times 2}$ are pre-determined hyperparameters;
  \item a bivariate beta distribution described in Appendix \ref{appendix:bivariate-beta-distribution}
  with parameters $\alpha_1, \dots, \alpha_4 \in \R_{>0}$.
\end{alineas}

If more studies about the same diagnostic test are available, a {\em
hierarchical partial pooling} approach can be adopted for prior specification,
as explained by \textcite[p. 1272-1274]{gelman2020bayesian} and by
\textcite[p. 2-3]{guo2017bayesian}.  

\subsection{Independent beta distribution priors}

If the knowledge of the specificity affects the range of most possible values
of the sensitivity, or vice-versa, there is antecedent information about the
correlation between the parameters. When this is not the case, a possible
independent prior formulation is the usage of $\betadist$ distribution since
it is bounded in the interval $[0,1]$ and it is reasonably flexible in its
shape.  Another good reason for this choice is that the beta distribution
forms a conjugate family with the likelihood binomial distribution (see Definition
\ref{def:conjugate-family}), which is more tractable numerically. Therefore we
have the following prior specification 
\begin{equation*}
  \begin{aligned}
    \gamma_s &\sim \betadist(a_s, b_s), \\
    \gamma_e &\sim \betadist(a_e, b_e), \\
  \end{aligned}
\end{equation*}
which leads to the following posterior distribution from the likelihood
\eqref{model:sensitivity-specificity}:
\begin{equation*}
  \begin{aligned}
    \gamma_s \mid y_{\mathrm{pos}} \sim \betadist(a_s + y_{\mathrm{pos}}, b_s + n_{\gamma_s} - y_{\mathrm{pos}}), \\
    \gamma_e \mid y_{\mathrm{neg}} \sim \betadist(a_e + y_{\mathrm{neg}}, b_e + n_{\gamma_e} - y_{\mathrm{neg}}). \\
  \end{aligned}
\end{equation*}

Notice that this particular likelihood function does not add any correlation to the
parameters since it treats each one separately. The interpretation of the beta
distribution parameter is in terms of the number of successes for the first
parameter and failures for the second parameter. With respect to Section
\ref{sec:correlation-sensitivity-specificity}, since the likelihood from this
model does not add any correlation to the posterior distribution, the prior
distribution has to give this information to it, when necessary.  

\subsection{Bivariate normal distribution in the log odds space}

This approach was designed by \textcite{chu2006bivariate} to jointly analyse 
sensitivity and specificity from a set o studies. In their work, the prior
specification allows the incorporation of regressors. We consider it without
the regressors, which simplifies to
\begin{equation*}
  \begin{pmatrix}
    \logit(\gamma_s) \\
    \logit(\gamma_e)
  \end{pmatrix}
\sim \operatorname{Normal}(\mu_{\gamma}, \Sigma_{\gamma}), \text{ with } \Sigma_{\gamma} =  
\begin{pmatrix}
  \sigma_{\gamma_s}^2 & \rho\sigma_{\gamma_s}\sigma_{\gamma_e} \\
  \rho\sigma_{\gamma_s}\sigma_{\gamma_e} & \sigma_{\gamma_e}^2  
\end{pmatrix},
\end{equation*}
such that $\sigma_{\gamma_s} > 0$ and $\sigma_{\gamma_e} > 0$ are the
standard deviations from log odds of sensitivity and specificity,
respectively, and $\rho$ is the correlation between the parameters in the log 
odds space. The possible problem with that prior approach is that the moments
of logit normal distribution are not in closed form and there is no available
formula to derive $\ev[\gamma_s]$ from the parameters of the normal
distribution \cite{kurt2021logit}. 

\subsection{A bivariate beta prior}

A common practice is to define the beta distribution as a prior distribution
over $[0,1]$. When more dimensions are necessary, the Dirichlet distribution
is a possible generalization with the restriction that the parameters live in
the simplex of lower dimension, i.e., if $\boldsymbol{x} \in [0,1]^d$ has Dirichlet
distribution, there is the restriction $\sum_{i=1}^d \boldsymbol{x}_i = 1$.
Because of that, \textcite{olkin2015constructions} build a bivariate beta distribution
with positive probability in $(0,1)^2$, with marginals having beta
distribution and correlation over the interval $(-1,1)$. Appendix
\ref{appendix:bivariate-beta-distribution} presents a detailed derivation. The
prior specification is as follows: 
\begin{equation*}
  \begin{aligned}
    (U_1, \dots, U_4) &\sim \operatorname{Dirichlet}(\alpha_1, \dots, \alpha_4), \\
    \gamma_e &= U_1 + U_2, \\
    \gamma_s &= U_1 + U_3.
  \end{aligned}
\end{equation*}
Prior distributions can be placed on the hyperparameters $\alpha_i$. In this work,
we employ 
\begin{equation*}
  \alpha_i \sim \operatorname{Gamma}(a^i, b^i), \quad a^i, b^i > 0, \quad \text{ for } i = 1,\dots,4. 
\end{equation*}
Suppose the research have prior information about specificity and specificity,
such their mean and correlation. 

To specify the prior hyperparameters using prior information, Section
\ref{sec:elicitation-bivariate-beta} discusses the results when the
researcher prespecifies $m_s = \ev[\gamma_s], m_e = \ev[\gamma_e], v_s = \var(\gamma_s),
v_e = \var(\gamma_e)$, and $\rho  = \cor(\gamma_s, \gamma_e)$. Since system
\eqref{eq:system-moments-alpha} usually has no solution, an optimization
problem is solved with $m_s$ and $m_e$ fixed, and the other parameters being
an approximation of the researcher's input values. For more details, see Appendix \ref{appendix:bivariate-beta-distribution}.

\begin{alineas}
  \item having $\alpha_i$ fixed: we search for $\alpha_i = \hat{\alpha}_i >
  0$ thorough the values of $m_s, m_e, \rho, v_s$, and $v_e$. An optimization
  problem is searching for $\hat{\alpha}_i$ which gives moments
  $\var(\gamma_s), \var(\gamma_e)$, and $\cor(\gamma_s, \gamma_e)$ as close as
  possible to the input values, and $m_s = \ev[\gamma_s], m_e =
  \ev[\gamma_e]$. A variation of this method would include $m_s$ and $m_e$ in
  the optimization problem and it is suggested when believes about $m_s$ and
  $m_e$ are less strong. 
  \item having $\alpha_i$ as a hierarchical parameter: we first estimate
  $\hat{\boldsymbol{\alpha}}$ the same way as described above and set
  $\ev[\alpha_i] = a^i/b^i = \hat{\alpha}_i \implies a^i = b^i\hat{\alpha}_i$.
  The parameter $b_i = \hat{\alpha}_i/\var(\alpha_i)$ is a inversely
  proportional quantity to the spread of parameter $\alpha_i$. The interesting
  thing about this approach is that it allows the prior to move more freely,
  specially when the input values are far from the estimated ones. 
\end{alineas}

\subsubsection*{Implementation of the dirichlet distribution in Stan}

The Dirichlet distribution is defined on the simplex of lower dimension.
Therefore the sampler has to consider the restriction of $\sum_{i=1}^4 U_i =
1$. \textcite{betancourt2012cruising} presents a simplification in the
structure of the simplex. The propose is \cite[p. 2]{betancourt2012cruising}
\begin{equation*}
  \begin{aligned}
    z_i &\sim \betadist(\tilde{\alpha}_i, \alpha_i), \text{ where } \tilde{\alpha}_i = \sum_{k=i+1}^4 \alpha_k, \quad i = 1,2,3 \\
    U_i &= \left(\prod_{k=1}^{i-1} z_k\right)\cdot \begin{cases}
      1 - z_i, &i < 4 \\
      1, &i = 4
    \end{cases},
  \end{aligned}
\end{equation*}
which removes the constraint. 

\begin{remark}
  When $\alpha$ is a random variable, the adapt delta parameter had to be
  increased to 0.9, since some divergences were found. 
\end{remark}

\subsection{Comparing the prior specifications with simulated data}

Now we are going to compare the three prior specification methods. For each of
the following three situations, we are going to simulate 1000 datasets from
the binomial likelihood with $n_{\gamma_s}, n_{\gamma_e} \sim
\operatorname{Poisson}(50)$, $\gamma_s \sim \betadist(100, 0.15/0.85 \cdot
100)$ to ensure $\ev[\gamma_s] = 0.85$, and  $\gamma_e \sim \betadist(100, 0.2/0.8 \cdot
100)$ to ensure $\ev[\gamma_e] = 0.8$. The three situations are: 

\begin{alineas}
  \item \label{item:vague-information-sensitivity-specificity} only vague information is available; 
  \item \label{item:strong-mean-sensitivity-specificity} strong beliefs about the means and no information about correlation; 
  \item\label{item:strong-mean-cor-information-sensitivity-specificity}  strong beliefs about the means and the correlation. 
\end{alineas}

For each situation and each dataset, it was drawn 2000 samples from the
posterior distribution and the HDI 75\% interval and posterior mean were calculated. The Hits
column counts the percentage of the times that the true values lied in the
interval, while the MSE column calculates the mean squared error of the
posterior mean with respect to the true value. We notice that the fourth prior
approach had a little number of effective samples when compared to the other
methods.  Notice that there is no big different among the approaches. The
logit normal prior is worst when strong information is given. This may be
related to the difficulty to convert information from the probability space to
the log odds space. The estimation error decreased when information about the 
means and correlation is given.
\autoref{fig:comparing_hdi_prior_approaches_sens-spec} 
shows that the credible intervals change very little for each different
approach and even for each quantity of information, which tells that the data 
is driving the posterior. 

\begin{table}[]
  \centering
  \caption{\label{tab:comparison-prior-approach-sensitivity-specificity}Comparing
  prior specification approaches in three different situations.}
  \begin{tabular}{cccccc}
    \hline
    \multirow{2}{*}{\textbf{Situation}} & \multirow{2}{*}{\textbf{Prior approach}} & \multicolumn{2}{c}{\textbf{Hits}} & \multicolumn{2}{c}{\textbf{MSE}} \\ \cline{3-6} 
     &  & \textbf{Sens} & \textbf{Spec} & \textbf{Sens} & \textbf{Spec} \\ \hline
    \multirow{4}{*}{\autoref{item:vague-information-sensitivity-specificity}} & Independent betas & 73.8\% & 76.1\% & 0.002531 & 0.002843 \\
     & Logit normal & 74.1\% & 74.5\% & 0.002405 & 0.002811 \\
     & Biv. beta constant $\alpha$ & 75.6\% & 75.5\% & 0.002388 & 0.002625 \\
     & Biv. beta random $\alpha$ & 74.9\% & 74.4\% & 0.002264 & 0.002546 \\
    \multirow{4}{*}{\autoref{item:strong-mean-sensitivity-specificity}} & Independent betas & 74.1\% & 73.6\% & 0.002009 & 0.002363 \\
     & Logit normal & 69.9\% & 71.2\% & 0.002300 & 0.002797 \\
     & Biv. beta constant $\alpha$ & 75.2\% & 75\% & 0.001952 & 0.002316 \\
     & Biv. beta random $\alpha$ & 74.7\% & 74.8\% & 0.002167 & 0.002454 \\
    \multirow{4}{*}{\autoref{item:strong-mean-cor-information-sensitivity-specificity}} & Independent betas & 74.3\% & 74.2\% & 0.002007 & 0.002365 \\
     & Logit normal & 68.4\% & 71.5\% & 0.002303 & 0.002804 \\
     & Biv. beta constant $\alpha$ & 74.3\% & 74.9\% & 0.001989 & 0.002364 \\
     & Biv. beta random $\alpha$ & 74.5\% & 75.5\% & 0.002229 & 0.002504 \\ \hline
    \end{tabular}
  \fonte{Prepared by the author (2021). Biv. means bivariate and Hits is the percentage of times that the estimated HDI 75\% included the true value.}
  \end{table}

\begin{figure}
  \centering
  \caption{\label{fig:comparing_hdi_prior_approaches_sens-spec} The mean HDI 75\% intervals
  for each prior strategy and level of information for sensitivity and specificity}
  \includegraphics[width=12cm]{comparing_hdi_prior_approaches_sens-spec.pdf}
  \fonte{Prepared by the author (2021).}
\end{figure}

By the above analysis, we choose the independent betas approach given it 
reduces the computational burden. 

\section{Imperfect tests}

A slight modification of model \eqref{model:perfect-tests} is to consider 
the imperfection of the test measured through specificity and sensitivity, 
remembering the relation of these quantities to the apparent prevalence
through equation \eqref{eq:apparent-true-prevalence}. Hence, the model can be
written as
\begin{equation}
  \label{model:imperfect-tests}
  \begin{aligned}
    Y_i \mid p_i &\sim \bern(p_i) \\
    p_i &= \gamma_s\theta_i + (1-\gamma_e)(1 - \theta_i),  \\
    g(\theta_i) &= g(\theta) + \x_i^T\beta,  \\
    \beta  &\sim \N(\mu_{\beta}, \Sigma_{\beta}), \\ 
    \theta &\sim \betadist(a^p, b^p), 
  \end{aligned}  
\end{equation}
with priors on $(\gamma_e, \gamma_s)$ as studied in the previous section. It is
important to highlight that we suppose prior the data that $\theta$ is
independent of $\gamma_e$ and $\gamma_s$, which is not necessarily true as
pointed out by \textcite{leeflang2013variation}, who concluded that
specificity tends to be lower when prevalence is higher. This 
is an extension of model presented by \textcite{gelman2020bayesian} and
studied by \textcite{mcinturff2004modelling}. 

\subsection{Identifiability}

If the regressors $\boldsymbol{x}_i$ are not present in model
\eqref{model:imperfect-tests}, it is no identifiable with respect to its
likelihood as pointed out by \textcite[p. 1271]{gelman2020bayesian}. 
Intuitively, the problem happens because $Y_i$ brings information about 
$p_i$ which is subdivided in three parameters: $\theta, \gamma_s$ and
$\gamma_e$. Regarding Definition \ref{def:identifiability} and dropping the
index $i$, take $\theta = 0.1, \gamma_e = 0.9$ and $\gamma_s = 0.6$. Then, 
\begin{equation*}
    p = 1 - \gamma_e + \frac{\gamma_s + \gamma_e - 1}{1 + e^{-g(\theta)}} = 0.15.
\end{equation*}
With $\gamma_e = 0.9$, $\gamma_s = 0.2$ and $\theta = 0.5$, the value of $p$
is also $0.15$, which implies that two
different combinations of the parameters generate the same probability
function for $Y$. As a consequence, the model is non-identifiable. Including the
regressors, the calculations are harder. Suppose that $g(\theta)$
is increased by a real $a$. The effect of $a$ on $p_i$ is through
$g^{-1}(g(\theta) + a + \boldsymbol{x}_i^T\beta)$, which depends on
$\boldsymbol{x}_i$. Because of that, sensitivity and specificity can not generally
offset this difference, and identifiability can not be proved or disproved. 

Nevertheless, there are some tractable cases. For instance, if $\boldsymbol{x}_i = x_i$ is a binary variable, with the same
reasoning, it can be shown that the model is not identifiable. Moreover the
problems concerning the covariates $\boldsymbol{X}$ appear here in the same
manner. To avoid any identifiability problem, information should be added by
the prior distribution, specially through $\gamma_s$ and $\gamma_s$. 

Below we present a practical situation where identifiability problems appear. 
We simulate data from the model with $\gamma_s = 0.8, \gamma_e = 0.85$ and
$\theta = 0.1$. Moreover $\beta \in \R^5$ and $\boldsymbol{X} \in \R^{200
\times 5}$ are chosen arbitrarily, the regressors being drawn from a normal
distribution. For the estimation process, uniform prior for $\theta, \gamma_s$
and $\gamma_e$, and a normal prior with mean 0 and standard deviation 1 for
each $\beta_i$. After 4000 iterations for warmup and 4000 for sampling, the
results are summarized in 
\autoref{tab:results-identifiability-imperfect-tests}
and \autoref{fig:posterior-trace-imperfect-tests-identifiability}. Notice that
the effective sample size is very small for the Bulk. The posterior mean are
very bad estimates for the true values. The high density set is test is the
union of two intervals for the prevalence, mich makes little sense in the real
life. 

\begin{table}[]
  \centering
  \caption{\label{tab:results-identifiability-imperfect-tests}Results from HMC
  algorithm for the practical identifiability analysis in model \eqref{model:imperfect-tests}.}
  \begin{tabular}{cccccccc}
    \hline
    \textbf{} & \textbf{mean} & \textbf{sd} & \textbf{mcse mean} &
    \textbf{mcse sd} & \textbf{ess bulk} & \textbf{ess tail} &
    \textbf{$\hat{R}$} \\ \hline
    $\theta$ & 0.500 & 0.340 & 0.022 & 0.016 & 291.0 & 3282.0 & 1.02 \\
    $\gamma_e$ & 0.585 & 0.277 & 0.019 & 0.015 & 231.0 & 2453.0 & 1.02 \\
    $\gamma_s$ & 0.415 & 0.279 & 0.020 & 0.014 & 241.0 & 2186.0 & 1.02 \\ \hline
  \end{tabular}
  \fonte{Prepared by the author (2021) as a result of Stan diagnostics output.
         The meaning of the columns is: mean is the posterior mean; sd is the
         posterior standard deviation; mcse mean is the mean Markov Chain Standard
         Error;  mcse sd is the standard deviation Markov Chain Standard
         error; ess bulk and ess tail are the Bulk and Tail effective sample
         sizes.}
\end{table}

\begin{figure}[ht]
  \centering
  \caption{\label{fig:posterior-trace-imperfect-tests-identifiability}Posterior
  distribution and trace plot of Prevalence, Specificity and Sensitivity for
  model \eqref{model:imperfect-tests} with vague priors.}
  \includegraphics[width=12cm]{posterior-trace-imperfect-tests-identifiability.pdf}
  \fonte{Prepared by the author (2021) with output of Stan.}
\end{figure}

\subsection{Simulated data}

As an initial check for model \eqref{model:imperfect-tests}, 
we use it to generate the data to verify if the estimation process
is sufficiently reliable. The experiment is similar to the one explained in
Section \ref{sec:perfect-test-identifiability}, but with sensitivity and 
specificity. We remind that vague priors on $\gamma_s$ and $\gamma_e$
are not recommended in general by the identifiability problem. We compare 
the estimates from model \eqref{model:perfect-tests} with these datasets.
\autoref{table:experiments-imperfect-test} summarizes the experiments. We use
a fixed $\beta = [-0.1, 2.5, 1.4, -1.8, 0.3]$ with two binary regressors and
three continuous drew from normal distribution. 

\begin{table}[!ht]
  \centering
  \caption{\label{table:experiments-imperfect-test}Experiment settings for the
  simulation of model \eqref{model:imperfect-tests}.}
  \begin{tabular}{ccccc}
  \hline
  Exp & $n$ & $\theta$ & $\gamma_s$ & $\gamma_e$ \\ \hline
  \multicolumn{1}{c}{1} & 100 & 0.1 & 0.9 & 0.8 \\
  \multicolumn{1}{c}{2} & 100 & 0.02 & 0.85 & 0.85 \\
  \multicolumn{1}{c}{3} & 2000 & 0.01 & 0.85 & 0.85 \\
  \multicolumn{1}{c}{4} & 2000 & 0.1 & 0.6 & 0.95 \\
  \multicolumn{1}{c}{5} & 2000 & 0.1 & 0.95 & 0.6 \\ 
  \multicolumn{1}{c}{6} & 2000 & 0.45 & 0.9 & 0.8 \\ \hline
  \end{tabular}
  \fonte{Prepared by the author (2021). We denote $n$ for number of samples.}
\end{table}



\section{Imperfect tests and respondent-driven sampling}

After understanding the problem with not considering the specificity and the
sensitivity of the diagnostic test for the estimation of $\theta$, we focus on the
sampling strategy studied in Section \ref{sec:respodent_driven_sampling}. 
One of the problems with RDS is that we can not make probability statements
without making assumptions about the sampling process. Since the participants
recruit their peers, the sampled individuals have a dependence on the
recruiters and on whom they recruited. In this section, we propose a model for
the network dependence of RDS extending \textcite{bastos2012binary}.

For now, the recruitment graph (see Definition \ref{def:recruitment-graph}) has no
uncertainty incorporated and it is included as a random effect on the model  
through a Conditionally autoregressive (CAR) model in the Gaussian case. This
model was developed for spatial effects, but they fit in this situation since
by adjacent sites we understand recruitment. We remark that for RDS, we
partially observe the corresponding map. If the whole map was available, we
could interpret it as interaction or friendship depending on the population. 


Let $[\tilde{Q}]_{ij} = \tilde{q}_{ij}$ be a fixed matrix which measures the distance between $i$
and $j$, and $\tilde{q}_{i+} = \sum_{j} \tilde{q}_{ij}$. In general, we use
$$
\tilde{q}_{ij} = \begin{cases}
  1, &\text{if } i \text{ recruited } j \text{ or the contrary} \\
  0, &\text{otherwise.} 
\end{cases}
$$
Next we define the scaled adjacency matrix $Q = D^{-1}\tilde{Q}$, such that $D$
is a diagonal matrix with $D_{ii} = \tilde{q}_{i+}$. Finally let $|\rho| < 1$ be a
parameter to controls the dependence between neighbors. Hence, we specify the
model as follows:

\begin{equation}
  \begin{aligned}
    T_i &\sim \bern(p_i) \\
    p_i &= \gamma_s\theta_i + (1-\gamma_e)(1 - \theta_i),  \\
    g(\theta_i) &= g(\theta) + \x_i^T\beta + \omega_i,  \\
    \omega_i|\{\omega_j\}_{j\neq i}, \tau &\sim \N\left(\rho\sum_j q_{ij}\omega_j, \tau^{-1}/\tilde{q}_{i+}\right) \\
    \beta &\sim \N(\mu, \Sigma), \\ 
    \theta &\sim \betadist(a^p, b^p) \\
    \gamma_s &\sim \betadist(a^s, b^s), \\
    \gamma_e &\sim \betadist(a^e, b^e), \\  
    \tau &\sim \operatorname{Gamma}(a^{\tau}, b^{\tau}).
  \end{aligned}  
\end{equation}
By Brook's Lemma \cite[]{brook1964distinction}, the joint distribution of
$\omega$ can be specified as 
$$
\omega \sim \N\left(0, \left[\tau (D - \rho \tilde{Q})\right]^{-1}\right).
$$

\subsection{Simulated data}

\begin{alineas}
  \item Between the model with the log odds of prevalence having a Gaussian prior
  distribution and the other with the prevalence having a Beta prior
  distribution, 
  the latter was usually faster and without divergences. Therefore the 
  preferable model is with the prevalence. 

  \item Non-centred distributions are really worst. 
  \item Comparison between parametrization of sigma and tau showed that
  they are similar in sight of time of execution, energy and divergences,
  among others diagnostics. However, the mean estimate of sigma is more
  controlled. The median estimate is very similar. This happens because there
  are a few very high samples for $\tau$ that will have high weight in the
  final result. Small samples for $\sigma$ have less impact, despite having
  some. 
  \item More sparse matrices (RDS data is very sparse) is generating the funil
  we do not want to see. This is not connected to the number of connected
  components. In order to see that, a simple example with the Erdos-Renyi
  Random Graph can answer to us. In the sparse case, the number of edges is
  $O(n)$ with $p=1/n$. If $p=1$, the number of edges is $O(n^2)$ and the funil
  disappears. This problem does not appear in the poisson model. 

  \item The effect of $\rho$ is really observed in the literature in the
  paper: ``A close look at the spatial structure implied by the CAR and SAR
  models''. 
\end{alineas}

\subsection{Exponential Random Graph Model (ERGM)}

RDS has the constraint of being without replacement. For that reason, we do
not observe all links among the samples \cite[]{crawford2016}. Considering the
model developed by Crawford, we can model the
matrix $Q$ as {\em Exponential Random Graph Model} (ERGM). Define the
following 

\begin{alineas}
  \item $\boldsymbol{s} = \tril(QC)^T \boldsymbol{1} + C^Tu$, such that $Q$ is the
  adjacency matrix of the recruited subjects, $C$ is the {\em Coupon Matrix},
  $u$ the vector of the number of edge ends belonging to each vertex
  (in the order of recruitment) that are not connected to any other sampled
  vertex, and $\tril(M)$ the lower triangle of $M$. 

  \item $T(Q) = -\lambda \boldsymbol{s}$, such that $\lambda$ is the rate of
  the recruitment time. 

  \item $V(Q) = \sum_{k \text{ is not seed}} \log(\lambda \boldsymbol{s}_k)$
  
  \item $w = (0, t_2 - t_1, ..., t_n - t_{n-1})$ is the worst.
  3. Comparison between parametrization of sigma and tau showed that they are
  similar in sight of time of execution, energy and divergences, among others
  diagnostics. However, the mean estimate of sigma is more controlled. The
  median estimate is very similar. This happens because there are a few very
   vector of the waiting times between
  recruitments.  
\end{alineas}

Therefore $\Pr(Q|w) \propto \exp[T(Q)^Tw + V(Q)]$. With that, the model
becomes 

\begin{equation}
  \begin{aligned}
    T_i &\sim \bern(p_i) \\
    p_i &= \gamma_s\theta_i + (1-\gamma_e)(1 - \theta_i),  \\
    g(\theta_i) &= g(\theta) + \x_i^T\beta + \omega_i,  \\
    \omega_i|\{\omega_j\}_{j\neq i}, \tau &\sim \N\left(\rho\sum_j q_{ij}\omega_j/q_{i+}, \tau^2/q_{i+}\right) \\
    Q|w &\propto \exp[T(Q)^Tw + V(Q)] \\
    \lambda &\sim \Gamma(a^{\lambda}, b^{\lambda}), \\ 
    \beta &\sim \N(\mu, \Sigma), \\ 
    \theta &\sim \betadist(a^p, b^p) \\
    \gamma_s &\sim \betadist(a^s, b^s), \\
    \gamma_e &\sim \betadist(a^e, b^e), \\  
    \tau &\sim \N^+(0,\sigma^2_{\tau}).
  \end{aligned}  
\end{equation}
The problem with this model is that we are assigning a posterior distribution
for $Q$.

\section{Model extensions}

Several characteristics of RDS were not include in the previous model, such as
homophily, bottlenecks, and sampling weights. This section aims to build some
options for these aspects and establish future works in that line. 

\begin{alineas}
  \item {\em Homophily model}: \cite{yauck2021general} 
  \item {\em Sampling weights}: GLM weighted
  \item {\em Bottlenecks}
\end{alineas}

\section{Mispecified data simulation}

